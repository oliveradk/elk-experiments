{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir(\"/Users/oliverdaniels-koch/projects/elk-experiments/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import random\n",
    "from itertools import cycle\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    \"\"\"Sets seed\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"/Users/oliverdaniels-koch/data/waterbird_complete95_forest2water2\"\n",
    "split_dict = {\"train\": \"train_metadata.csv\", \"val\": \"val_metadata.csv\", \"test\": \"test_metadata.csv\"}\n",
    "dataset = load_dataset(dataset_dir, data_files=split_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.remove_columns([\"img_id\", \"place_filename\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.rename_column(\"y\", \"labels\")\n",
    "dataset = dataset.rename_column(\"place\", \"aux_labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove instances on train set where y != place \n",
    "dataset[\"train\"] = dataset[\"train\"].filter(lambda x: x[\"labels\"] == x[\"aux_labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all([label == aux_label for label, aux_label in zip(dataset[\"train\"][\"labels\"], dataset[\"train\"][\"aux_labels\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, ResNetForImageClassification\n",
    "processor = AutoImageProcessor.from_pretrained(\"microsoft/resnet-50\")\n",
    "model = ResNetForImageClassification.from_pretrained(\"microsoft/resnet-50\", num_labels=2, ignore_mismatched_sizes=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_heads = 2\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Flatten(start_dim=1, end_dim=-1), \n",
    "    nn.Linear(in_features=2048, out_features=n_heads * 2, bias=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_filename = dataset[\"train\"][\"img_filename\"][0]\n",
    "image = Image.open(os.path.join(dataset_dir, image_filename)).convert(\"RGB\")\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_images(examples):\n",
    "    examples[\"pixel_values\"] = torch.concat([\n",
    "        processor(Image.open(os.path.join(dataset_dir, img_filename)), return_tensors=\"pt\").pixel_values \n",
    "        for img_filename in examples[\"img_filename\"]\n",
    "    ])\n",
    "    del examples[\"img_filename\"]\n",
    "    return examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.with_transform(transform_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divdis loss\n",
    "# from https://github.com/yoonholee/DivDis/blob/main/divdis.py\n",
    "# TODO: understand this code\n",
    "from einops import rearrange\n",
    "\n",
    "def to_probs(logits, heads):\n",
    "    \"\"\"\n",
    "    Converts logits to probabilities.\n",
    "    Input must have shape [batch_size, heads * classes].\n",
    "    Output will have shape [batch_size, heads, classes].\n",
    "    \"\"\"\n",
    "\n",
    "    B, N = logits.shape\n",
    "    logits_chunked = torch.chunk(logits, heads, dim=-1)\n",
    "    probs = torch.stack(logits_chunked, dim=1).softmax(-1)\n",
    "    B, H, D = probs.shape\n",
    "    assert H == heads\n",
    "    return probs\n",
    "\n",
    "class DivDisLoss(nn.Module):\n",
    "    \"\"\"Computes pairwise repulsion losses for DivDis.\n",
    "\n",
    "    Args:\n",
    "        logits (torch.Tensor): Input logits with shape [BATCH_SIZE, HEADS * DIM].\n",
    "        heads (int): Number of heads.\n",
    "        mode (str): DIVE loss mode. One of {pair_mi, total_correlation, pair_l1}.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, heads):\n",
    "        super().__init__()\n",
    "        self.heads = heads\n",
    "\n",
    "    def forward(self, logits):\n",
    "        heads = self.heads\n",
    "        probs = to_probs(logits, heads)\n",
    "\n",
    "        marginal_p = probs.mean(dim=0)  # H, D\n",
    "        marginal_p = torch.einsum(\n",
    "            \"hd,ge->hgde\", marginal_p, marginal_p\n",
    "        )  # H, H, D, D\n",
    "        marginal_p = rearrange(marginal_p, \"h g d e -> (h g) (d e)\")  # H^2, D^2\n",
    "\n",
    "        joint_p = torch.einsum(\"bhd,bge->bhgde\", probs, probs).mean(\n",
    "            dim=0\n",
    "        )  # H, H, D, D\n",
    "        joint_p = rearrange(joint_p, \"h g d e -> (h g) (d e)\")  # H^2, D^2\n",
    "\n",
    "        # Compute pairwise mutual information = KL(P_XY | P_X x P_Y)\n",
    "        # Equivalent to: F.kl_div(marginal_p.log(), joint_p, reduction=\"none\")\n",
    "        kl_computed = joint_p * (joint_p.log() - marginal_p.log())\n",
    "        kl_computed = kl_computed.sum(dim=-1)\n",
    "        kl_grid = rearrange(kl_computed, \"(h g) -> h g\", h=heads)\n",
    "        repulsion_grid = -kl_grid\n",
    "\n",
    "        repulsion_grid = torch.triu(repulsion_grid, diagonal=1)\n",
    "        repulsions = repulsion_grid[repulsion_grid.nonzero(as_tuple=True)]\n",
    "        repulsion_loss = -repulsions.mean()\n",
    "\n",
    "        return repulsion_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Categorical, kl_divergence\n",
    "\n",
    "class RegLoss(nn.Module):\n",
    "    def __init__(self, n_heads, n_classes):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "    def forward(self, source_logits, target_logits):\n",
    "        source_logits_chunked = torch.chunk(source_logits, self.n_heads, dim=-1) # [[B, C] * H]\n",
    "        target_logits_chunked = torch.chunk(target_logits, self.n_heads, dim=-1) # [[B, C] * H]\n",
    "        source_logits = torch.stack(source_logits_chunked, dim=1) # [B, H, C]\n",
    "        target_logits = torch.stack(target_logits_chunked, dim=1) # [B, H, C]\n",
    "        avg_preds_source = source_logits.softmax(dim=-1).mean(dim=[0,1]) # [C]\n",
    "        target_preds = target_logits.softmax(dim=-1) # [B, H, C]\n",
    "        avg_preds_target = target_preds.mean(dim=1) # [B, C]\n",
    "        dist_source = Categorical(probs=avg_preds_source)\n",
    "        dist_target = Categorical(probs=avg_preds_target)\n",
    "        reg_loss = kl_divergence(dist_source, dist_target).mean()\n",
    "        return reg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross entropy loss with multiple heads \n",
    "class CrossEntropyLossHeads(nn.Module):\n",
    "    def __init__(self, n_heads):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, logits, labels):\n",
    "        logits_chunked = torch.chunk(logits, self.n_heads, dim=-1)\n",
    "        losses = [self.loss(logits, labels) for logits in logits_chunked]\n",
    "        return sum(losses) / self.n_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hparams \n",
    "batch_size = 16\n",
    "num_epochs = 10\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-4\n",
    "momentum = 0.9\n",
    "diversity_weight = 100\n",
    "reg_weight = 10\n",
    "\n",
    "device = \"mps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = CrossEntropyLossHeads(n_heads)\n",
    "dividis_loss = DivDisLoss(n_heads)\n",
    "reg_loss = RegLoss(n_heads, 2)\n",
    "# hmm, do I need separate optimizers for the heads?\n",
    "# hmm, for some reason SGD gives degenerate results\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "train_loader = torch.utils.data.DataLoader(dataset[\"train\"], batch_size=batch_size, shuffle=True)\n",
    "target_loader = torch.utils.data.DataLoader(dataset[\"val\"], batch_size=batch_size, shuffle=False)\n",
    "val_lodaer = torch.utils.data.DataLoader(dataset[\"test\"], batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: log to tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train loop with accuracy logging\n",
    "model.to(device)\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    progress_bar = tqdm(zip(train_loader, cycle(target_loader)), total=len(train_loader), desc=f\"train Epoch {epoch}\")\n",
    "    for train_batch, target_batch in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(pixel_values=train_batch[\"pixel_values\"].to(device))\n",
    "        target_outputs = model(pixel_values=target_batch[\"pixel_values\"].to(device))\n",
    "        loss_value = loss(outputs.logits, train_batch[\"labels\"].to(device))\n",
    "        divdis_loss_value = dividis_loss(target_outputs.logits)\n",
    "        reg_loss_value = reg_loss(outputs.logits, target_outputs.logits)\n",
    "        total_loss_value = loss_value + divdis_loss_value * diversity_weight + reg_loss_value * reg_weight\n",
    "        total_loss_value.backward()\n",
    "        optimizer.step()\n",
    "        progress_bar.set_postfix({\"training_loss\": f\"{loss_value.item():.3f}\",\n",
    "                                  \"divdis_loss\": f\"{divdis_loss_value.item():.5f}\",\n",
    "                                  \"reg_loss\": f\"{reg_loss_value.item():.3f}\",\n",
    "                                  \"total_loss\": f\"{total_loss_value.item():.3f}\"})\n",
    "    model.eval()\n",
    "    correct = np.zeros(n_heads)\n",
    "    correct_aux = np.zeros(n_heads)\n",
    "    total = 0\n",
    "    # TODO: evaluate on aux labels too\n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(val_lodaer, desc=f\"val Epoch {epoch}\")\n",
    "        for batch in progress_bar:\n",
    "            outputs = model(pixel_values=batch[\"pixel_values\"].to(device)) # (batch, heads * classes)\n",
    "            chunked_logits = torch.chunk(outputs.logits, n_heads, dim=-1) # [[batch, classes] * heads]\n",
    "            predictions = torch.stack([logits.argmax(dim=-1) for logits in chunked_logits], dim=1) # (batch, heads)\n",
    "            correct += (predictions == batch[\"labels\"].unsqueeze(-1).to(device)).sum(dim=0).cpu().numpy()\n",
    "            correct_aux += (predictions == batch[\"aux_labels\"].unsqueeze(-1).to(device)).sum(dim=0).cpu().numpy()\n",
    "            total += batch[\"labels\"].shape[0]\n",
    "    for i in range(n_heads):\n",
    "        print(f\"head {i}: Epoch {epoch}: Accuracy: {correct[i] / total} (aux: {correct_aux[i] / total})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    progress_bar = tqdm(val_lodaer, desc=f\"val Epoch {epoch}\")\n",
    "    for batch in progress_bar:\n",
    "        outputs = model(pixel_values=batch[\"pixel_values\"].to(device)) # (batch, heads * classes)\n",
    "        chunked_logits = torch.chunk(outputs.logits, n_heads, dim=-1) # [[batch, classes] * heads]\n",
    "        predictions = torch.stack([logits.argmax(dim=-1) for logits in chunked_logits], dim=1) # (batch, heads)\n",
    "        correct += (predictions == batch[\"labels\"].unsqueeze(-1).to(device)).sum(dim=0).cpu().numpy()\n",
    "        correct_aux += (predictions == batch[\"aux_labels\"].unsqueeze(-1).to(device)).sum(dim=0).cpu().numpy()\n",
    "        total += batch[\"labels\"].shape[0]\n",
    "for i in range(n_heads):\n",
    "    print(f\"head {i}: Epoch {epoch}: Accuracy: {correct[i] / total} (aux: {correct_aux[i] / total})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elk-experiments-AZ2LBS3Q-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
