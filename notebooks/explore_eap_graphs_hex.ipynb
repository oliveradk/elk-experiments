{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "os.chdir(\"/Users/oliverdaniels-koch/projects/elk-experiments\")\n",
    "out_dir = Path(\"output\")\n",
    "device = \"mps\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore EAP Graphs on Hex\n",
    "\n",
    "I'm curious if we see notable differences when running (aggregated) edge attribution patching \n",
    "on the trusted and untrusted data of the hex task\n",
    "\n",
    "I suspect there's a lot of in-distribution variation, but maybe we'll see two distinct circuits?\n",
    "\n",
    "I also want to create a detector using k-means clustering?\n",
    "\n",
    "I guess there's just a bunch of ways to learn a latent space of the adjacency / score matrix\n",
    "\n",
    "Seems like there should be something smarter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import torch \n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cupbearer.tasks import tiny_natural_mechanisms\n",
    "from elk_experiments.tiny_natural_mechanisms_utils import get_task_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model attn-only-1l into HookedTransformer\n",
      "Moving model to device:  mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliverdaniels-koch/Library/Caches/pypoetry/virtualenvs/elk-experiments-AZ2LBS3Q-py3.10/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model pythia-70m into HookedTransformer\n",
      "Moving model to device:  mps\n"
     ]
    }
   ],
   "source": [
    "task = tiny_natural_mechanisms(\"hex\", device, \"pythia-70m\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.model.set_use_hook_mlp_in(True)\n",
    "task.model.set_use_split_qkv_input(True)\n",
    "task.model.set_use_attn_result(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_task = get_task_subset(task, 2048, 1048, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eap.eap_wrapper import EAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use mean probability over effect tokens as metric \n",
    "def effect_prob_func(logits, effect_tokens):\n",
    "    assert logits.ndim == 3\n",
    "    # Sum over vocab and batch dim (for now we're just computing attribution values, we'll deal with per data instance later)\n",
    "    probs = logits[:, -1, :].softmax(dim=-1)\n",
    "    out = probs[:, effect_tokens].mean(dim=-1).mean() # mean over effect tokens, mean over batch\n",
    "    # out = logits[:, -1, effect_tokens].mean()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cupbearer.tasks.tiny_natural_mechanisms import get_effect_tokens\n",
    "effect_tokens = get_effect_tokens(\"hex\", task.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "trusted_tokens = torch.stack([torch.tensor(data[\"prefix_tokens\"]) for data in small_task.trusted_data.data])\n",
    "untrusted_clean_tokens = torch.stack([torch.tensor(data[\"prefix_tokens\"]) for data in small_task.test_data.normal_data.data])\n",
    "anomalous_tokens = torch.stack([torch.tensor(data[\"prefix_tokens\"]) for data in small_task.test_data.anomalous_data.data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2048, 16]), torch.Size([1024, 16]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trusted_tokens.shape, anomalous_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving activations requires 0.0001 GB of memory per token\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/Users/oliverdaniels-koch/Library/Caches/pypoetry/virtualenvs/elk-experiments-AZ2LBS3Q-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1344: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "100%|██████████| 32/32 [01:48<00:00,  3.40s/it]\n"
     ]
    }
   ],
   "source": [
    "task.model.reset_hooks()\n",
    "\n",
    "clean_graph = EAP(\n",
    "    model=task.model,\n",
    "    clean_tokens=trusted_tokens,\n",
    "    metric=partial(effect_prob_func, effect_tokens=effect_tokens),\n",
    "    upstream_nodes=[\"head\"],\n",
    "    downstream_nodes=[\"head\"],\n",
    "    batch_size=64,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(graph, threshold=None, abs_scores=None, fname=\"eap_graph.png\", fdir=None):\n",
    "    import pygraphviz as pgv\n",
    "\n",
    "    minimum_penwidth = 0.2\n",
    "    edges = graph.top_edges(threshold=threshold, abs_scores=abs_scores)\n",
    "\n",
    "    g = pgv.AGraph(\n",
    "        name='root',\n",
    "        strict=True,\n",
    "        directed=True\n",
    "    )\n",
    "\n",
    "    g.graph_attr.update(ranksep='0.1', nodesep='0.1', compound=True)\n",
    "    g.node_attr.update(fixedsize='true', width='1.5', height='.5')\n",
    "\n",
    "    def find_layer_node(node):\n",
    "        if node == f'resid_post.{graph.cfg.n_layers - 1}':\n",
    "            return graph.cfg.n_layers\n",
    "        else:\n",
    "            return int(node.split(\".\")[1])\n",
    "\n",
    "    layer_to_subgraph = {}\n",
    "    layer_to_subgraph[-1] = g.add_subgraph(name=f'cluster_-1', rank='same', color='invis')\n",
    "    layer_to_subgraph[-1].add_node(f'-1_invis', style='invis')\n",
    "\n",
    "    min_layer = 999\n",
    "    max_layer = -1\n",
    "    layers = list(range(0, 32))\n",
    "\n",
    "    for edge in edges:\n",
    "        parent_node = edge[0]\n",
    "        child_node = edge[1]\n",
    "        min_layer = min(min_layer, find_layer_node(parent_node))\n",
    "        max_layer = max(max_layer, find_layer_node(child_node))\n",
    "\n",
    "    layers = list(range(min_layer, max_layer + 1))\n",
    "    prev_layer = None\n",
    "\n",
    "    for layer in layers:\n",
    "        layer_to_subgraph[layer] = g.add_subgraph(name=f'cluster_{layer}', rank='same', color='invis')\n",
    "        layer_to_subgraph[layer].add_node(f'{layer}_invis', style='invis')\n",
    "\n",
    "        if prev_layer is not None:\n",
    "            g.add_edge(f'{prev_layer}_invis', f'{layer}_invis', style='invis', weight=1000)\n",
    "\n",
    "        prev_layer = layer\n",
    "                \n",
    "    # Adding nodes and edges between nodes\n",
    "    for edge in edges:\n",
    "        parent_node, child_node, edge_score = edge\n",
    "\n",
    "        parent_name = parent_node\n",
    "        child_name = child_node\n",
    "\n",
    "        child_name = child_name.replace(\".q\", \"\").replace(\".k\", \"\").replace(\".v\", \"\")\n",
    "        \n",
    "        for node_name in [parent_name, child_name]:\n",
    "\n",
    "            node_layer = find_layer_node(node_name)\n",
    "\n",
    "            node_color = '#1f77b4' if node_name.startswith(\"head\") else '#ff7f0e' if node_name.startswith(\"mlp\") else '#2ca02c' if node_name.startswith(\"resid\") else '#d62728'\n",
    "\n",
    "            layer_to_subgraph[node_layer].add_node(\n",
    "                node_name,\n",
    "                fillcolor=node_color,\n",
    "                color=\"black\",\n",
    "                style=\"filled, rounded\",\n",
    "                shape=\"box\",\n",
    "                fontname=\"Helvetica\",\n",
    "            )\n",
    "            \n",
    "        edge_width = str(max(minimum_penwidth, edge_score*100))\n",
    "\n",
    "        g.add_edge(\n",
    "            parent_name,\n",
    "            child_name,\n",
    "            penwidth=edge_width,\n",
    "            color='#0091E4',\n",
    "            weight=10,\n",
    "            minlen='0.5',\n",
    "        )\n",
    "    # fdir = fdir if fdir is not None else DEFAULT_GRAPH_PLOT_DIR\n",
    "    save_path = os.path.join(fdir, fname)\n",
    "    print(f\"Saving graph\")\n",
    "    if not fname.endswith(\".gv\"): # turn the .gv file into a .png file\n",
    "        g.draw(path=save_path, prog='dot')\n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving graph\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AGraph b'root' <Swig Object of type 'Agraph_t *' at 0x32953e8e0>>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show(clean_graph, threshold=9e-8, abs_scores=False, fdir=out_dir, fname=\"clean_graph.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_edges = clean_graph.top_edges(threshold=5e-8, abs_scores=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('head.0.3', 'head.1.3.v', 3.1783656595507637e-07),\n",
       " ('head.0.3', 'head.1.4.v', 1.4391096669896797e-07),\n",
       " ('head.0.6', 'head.3.3.v', 1.400565281528543e-07),\n",
       " ('head.0.6', 'head.3.1.v', 1.2082939804258785e-07),\n",
       " ('head.2.5', 'head.3.1.v', 1.0892620139202336e-07),\n",
       " ('head.0.0', 'head.2.1.v', 9.165699310642594e-08),\n",
       " ('head.0.6', 'head.1.0.v', 8.914732063658448e-08),\n",
       " ('head.0.3', 'head.1.0.v', 8.54735233701831e-08),\n",
       " ('head.1.3', 'head.3.3.v', 7.186512362977737e-08),\n",
       " ('head.0.3', 'head.3.7.v', 6.30051957273281e-08),\n",
       " ('head.1.3', 'head.3.7.v', 6.278842334950241e-08),\n",
       " ('head.1.4', 'head.3.1.v', 6.268881946880356e-08),\n",
       " ('head.0.7', 'head.3.7.v', 6.248009754017403e-08),\n",
       " ('head.2.6', 'head.3.7.v', 5.96108336026191e-08),\n",
       " ('head.0.3', 'head.2.4.v', 5.65856090872785e-08),\n",
       " ('head.3.1', 'head.4.0.v', 5.586666063095436e-08),\n",
       " ('head.2.6', 'head.3.2.v', 5.513895828812565e-08),\n",
       " ('head.0.4', 'head.3.7.v', 5.440797679057141e-08),\n",
       " ('head.0.1', 'head.1.7.v', 5.3475812222814056e-08),\n",
       " ('head.0.5', 'head.2.4.v', 5.2043446885363664e-08),\n",
       " ('head.0.4', 'head.2.0.v', 5.175467876483708e-08)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving activations requires 0.0001 GB of memory per token\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]/Users/oliverdaniels-koch/Library/Caches/pypoetry/virtualenvs/elk-experiments-AZ2LBS3Q-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1344: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "100%|██████████| 16/16 [00:56<00:00,  3.53s/it]\n"
     ]
    }
   ],
   "source": [
    "task.model.reset_hooks()\n",
    "\n",
    "anomalous_graph = EAP(\n",
    "    model=task.model,\n",
    "    clean_tokens=anomalous_tokens,\n",
    "    metric=partial(effect_prob_func, effect_tokens=effect_tokens),\n",
    "    upstream_nodes=[\"head\"],\n",
    "    downstream_nodes=[\"head\"],\n",
    "    batch_size=64,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving graph\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AGraph b'root' <Swig Object of type 'Agraph_t *' at 0x3295adec0>>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show(anomalous_graph, threshold=9e-8, abs_scores=False, fdir=out_dir, fname=\"anomalous_graph.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalous_edges = anomalous_graph.top_edges(threshold=9e-8, abs_scores=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('head.0.3', 'head.1.3.v', 4.6406509568441834e-07),\n",
       " ('head.0.3', 'head.1.4.v', 2.5037650175363524e-07),\n",
       " ('head.0.6', 'head.3.3.v', 1.8278846880548372e-07),\n",
       " ('head.0.3', 'head.1.0.v', 1.727667182649384e-07),\n",
       " ('head.0.6', 'head.3.1.v', 1.5554519450233784e-07),\n",
       " ('head.0.6', 'head.1.0.v', 1.4941561232717504e-07),\n",
       " ('head.2.5', 'head.3.1.v', 1.4546419890848483e-07),\n",
       " ('head.0.7', 'head.1.3.v', 1.2531749860045238e-07),\n",
       " ('head.1.3', 'head.3.1.v', 1.079033751238967e-07),\n",
       " ('head.1.3', 'head.2.6.q', 1.0309624087767588e-07),\n",
       " ('head.3.1', 'head.4.0.v', 1.0156108487535676e-07),\n",
       " ('head.0.3', 'head.3.7.v', 9.93367237356324e-08),\n",
       " ('head.1.4', 'head.3.1.v', 9.449505000702629e-08),\n",
       " ('head.0.6', 'head.2.0.v', 9.381216159454198e-08),\n",
       " ('head.0.5', 'head.2.6.k', 9.37108524112773e-08),\n",
       " ('head.0.0', 'head.2.1.v', 9.233470876779393e-08)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomalous_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving activations requires 0.0001 GB of memory per token\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]/Users/oliverdaniels-koch/Library/Caches/pypoetry/virtualenvs/elk-experiments-AZ2LBS3Q-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1344: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "100%|██████████| 16/16 [00:58<00:00,  3.64s/it]\n"
     ]
    }
   ],
   "source": [
    "task.model.reset_hooks()\n",
    "\n",
    "unstrusted_clean_graph = EAP(\n",
    "    model=task.model,\n",
    "    clean_tokens=untrusted_clean_tokens,\n",
    "    metric=partial(effect_prob_func, effect_tokens=effect_tokens),\n",
    "    upstream_nodes=[\"head\"],\n",
    "    downstream_nodes=[\"head\"],\n",
    "    batch_size=64,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving graph\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AGraph b'root' <Swig Object of type 'Agraph_t *' at 0x2f76d3c60>>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show(unstrusted_clean_graph, threshold=9e-8, abs_scores=False, fdir=out_dir, fname=\"untrusted_clean_graph.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Using Set Difference As anomaly score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Getting Top Edges across Entire Distribution, filtering anomolies with respect to that"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elk-experiments-AZ2LBS3Q-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
