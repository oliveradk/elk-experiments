{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from IPython.display import Image, display\n",
    "os.chdir(\"/Users/oliverdaniels-koch/projects/elk-experiments\")\n",
    "out_dir = Path(\"output\")\n",
    "device = \"mps\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore EAP Graphs on Hex\n",
    "\n",
    "I'm curious if we see notable differences when running (aggregated) edge attribution patching \n",
    "on the trusted and untrusted data of the hex task\n",
    "\n",
    "I suspect there's a lot of in-distribution variation, but maybe we'll see two distinct circuits?\n",
    "\n",
    "I also want to create a detector using k-means clustering?\n",
    "\n",
    "I guess there's just a bunch of ways to learn a latent space of the adjacency / score matrix\n",
    "\n",
    "Seems like there should be something smarter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens import HookedEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "\n",
    "import torch \n",
    "import numpy as np\n",
    "\n",
    "from cupbearer import tasks, detectors, scripts, utils\n",
    "from cupbearer.detectors import ActivationCache\n",
    "from cupbearer.detectors.statistical import MahalanobisDetector\n",
    "from cupbearer.tasks.tiny_natural_mechanisms import get_effect_tokens\n",
    "from elk_experiments.utils import train_detector_cache, learn_graph_cache, get_activation_at_last_token\n",
    "from elk_experiments.tiny_natural_mechanisms_utils import get_task_subset\n",
    "from elk_experiments.eap_detector import EAPDetector, layer_edge_filter, effect_prob_func, set_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"ifelse\"\n",
    "model_name = \"pythia-70m\"\n",
    "nodes = [\"head\", \"mlp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_dir = out_dir / f\"subset_graphs_{task_name}_{model_name}_{'_'.join(nodes)}\"\n",
    "graph_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = tasks.tiny_natural_mechanisms(task_name, device, model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.model.set_use_hook_mlp_in(True)\n",
    "task.model.set_use_split_qkv_input(True)\n",
    "task.model.set_use_attn_result(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_task = get_task_subset(task, 2048, 1048, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "effect_tokens = get_effect_tokens(task_name, task.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trusted_tokens = torch.stack([torch.tensor(data[\"prefix_tokens\"]) for data in small_task.trusted_data.data])\n",
    "untrusted_clean_tokens = torch.stack([torch.tensor(data[\"prefix_tokens\"]) for data in small_task.test_data.normal_data.data])\n",
    "anomalous_tokens = torch.stack([torch.tensor(data[\"prefix_tokens\"]) for data in small_task.test_data.anomalous_data.data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if task_name == \"ifelse\":\n",
    "    threshold = 2e-6\n",
    "elif task_name == \"hex\":\n",
    "    threshold = 1e-7\n",
    "else: \n",
    "    raise ValueError(\"task not recognized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trusted Data Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_graph_path = graph_dir / \"clean_graph.pt\"\n",
    "task.model.reset_hooks()\n",
    "\n",
    "clean_graph = learn_graph_cache(\n",
    "    model=task.model,\n",
    "    tokens=trusted_tokens,\n",
    "    metric=partial(effect_prob_func, effect_tokens=effect_tokens),\n",
    "    upstream_nodes=[\"head\"],\n",
    "    downstream_nodes=[\"head\"],\n",
    "    batch_size=128,\n",
    "    cache_path=clean_graph_path,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_graph.top_edges(n=20, abs_scores=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"clean_graph.png\"\n",
    "clean_graph.show(threshold=threshold, abs_scores=False, fdir=graph_dir, fname=fname)\n",
    "display(Image(graph_dir / fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_edges = clean_graph.top_edges(threshold=threshold, abs_scores=False)\n",
    "len(clean_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomalous Data Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalous_graph_path = graph_dir / \"anomalous_graph.pt\"\n",
    "\n",
    "task.model.reset_hooks()\n",
    "\n",
    "anomalous_graph = learn_graph_cache(\n",
    "    model=task.model,\n",
    "    tokens=anomalous_tokens,\n",
    "    metric=partial(effect_prob_func, effect_tokens=effect_tokens),\n",
    "    upstream_nodes=[\"head\"],\n",
    "    downstream_nodes=[\"head\"],\n",
    "    batch_size=128,\n",
    "    cache_path=anomalous_graph_path,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"anom_graph.png\"\n",
    "anomalous_graph.show(threshold=threshold, abs_scores=False, fdir=graph_dir, fname=fname)\n",
    "display(Image(graph_dir / fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalous_edges = anomalous_graph.top_edges(threshold=threshold, abs_scores=False)\n",
    "len(anomalous_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Untrusted Clean Data Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.model.reset_hooks()\n",
    "\n",
    "untrusted_clean_path = graph_dir / \"untrusted_clean_graph.pt\"\n",
    "\n",
    "untrusted_clean_graph = learn_graph_cache(\n",
    "    model=task.model,\n",
    "    tokens=untrusted_clean_tokens,\n",
    "    metric=partial(effect_prob_func, effect_tokens=effect_tokens),\n",
    "    upstream_nodes=[\"head\"],\n",
    "    downstream_nodes=[\"head\"],\n",
    "    batch_size=128,\n",
    "    cache_path=untrusted_clean_path,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untrusted_clean_graph.top_edges(threshold=2e-6, abs_scores=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"untrusted_clean_graph.png\"\n",
    "untrusted_clean_graph.show(threshold=2e-6, abs_scores=False, fdir=graph_dir, fname=fname)\n",
    "display(Image(graph_dir / fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untrusted_clean_edges = untrusted_clean_graph.top_edges(threshold=threshold, abs_scores=False)\n",
    "len(untrusted_clean_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = torch.cat([trusted_tokens, anomalous_tokens, untrusted_clean_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_graph_path = graph_dir / \"full_graph.pt\"\n",
    "\n",
    "task.model.reset_hooks()\n",
    "\n",
    "full_graph = learn_graph_cache(\n",
    "    task.model,\n",
    "    all_tokens,\n",
    "    partial(effect_prob_func, effect_tokens=effect_tokens),\n",
    "    upstream_nodes=nodes,\n",
    "    downstream_nodes=nodes,\n",
    "    batch_size=128,\n",
    "    cache_path=full_graph_path,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"full_graph.png\"\n",
    "full_graph.show(threshold=threshold, abs_scores=True, fname=fname, fdir=graph_dir)\n",
    "display(Image(graph_dir / fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_edges = full_graph.top_edges(threshold=threshold, abs_scores=True)\n",
    "len(full_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Untrusted Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untrusted_tokens = torch.cat([anomalous_tokens, untrusted_clean_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untrusted_path = graph_dir / \"untrusted_graph.pt\"\n",
    "\n",
    "task.model.reset_hooks()\n",
    "\n",
    "untrusted_graph = learn_graph_cache(\n",
    "    task.model,\n",
    "    untrusted_tokens,\n",
    "    partial(effect_prob_func, effect_tokens=effect_tokens),\n",
    "    upstream_nodes=[\"head\"],\n",
    "    downstream_nodes=[\"head\"],\n",
    "    batch_size=128,\n",
    "    cache_path=untrusted_path,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"untrusted_graph.png\"\n",
    "untrusted_graph.show(threshold=threshold, abs_scores=False, fname=fname, fdir=graph_dir)\n",
    "display(Image(graph_dir / fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untrusted_edges = untrusted_graph.top_edges(threshold=threshold, abs_scores=False)\n",
    "len(untrusted_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detectors Using EAP Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elk_experiments.utils import train_detector_cache\n",
    "from elk_experiments.eap_detector import EAPDetector\n",
    "from cupbearer.detectors import ActivationCache\n",
    "from cupbearer.detectors import MahalanobisDetector\n",
    "from cupbearer import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EAPMahalanobisDetector(EAPDetector, MahalanobisDetector):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_set_filter(edge, edge_set):\n",
    "    return tuple(edge) in edge_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe the problem is that the psedoinverse basically compresses the dimensions of variation between the training and test data\n",
    "\n",
    "# should try more basic method (number of anomolous edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cache = ActivationCache(device)\n",
    "detector_dir = graph_dir / \"standard_detector\"\n",
    "\n",
    "detector = EAPMahalanobisDetector(\n",
    "    effect_prob_func=partial(effect_prob_func, effect_tokens=effect_tokens),\n",
    "    upstream_nodes=[\"head\"],\n",
    "    downstream_nodes=[\"head\"],\n",
    "    edge_filter=lambda x: True,\n",
    "    layer_aggregation=\"mean\", \n",
    "    cache=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-07-13 01:52:27.393\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcupbearer.detectors.statistical.statistical\u001b[0m:\u001b[36minit_variables\u001b[0m:\u001b[36m83\u001b[0m - \u001b[34m\u001b[1mActivation sizes: \n",
      "eap_scores: torch.Size([4032])\u001b[0m\n",
      " 31%|███       | 79/256 [08:41<19:27,  6.60s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_detector_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdetector_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetector_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdetector\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetector\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/elk-experiments/elk_experiments/utils.py:45\u001b[0m, in \u001b[0;36mtrain_detector_cache\u001b[0;34m(detector_dir, detector, task, batch_size, eval_batch_size, cache, cache_path, overwrite, overwrite_cache, **train_kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m     out \u001b[38;5;241m=\u001b[39m scripts\u001b[38;5;241m.\u001b[39meval_detector(task, detector, save_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, batch_size\u001b[38;5;241m=\u001b[39meval_batch_size, pbar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 45\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mscripts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_detector\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetector_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrain_kwargs\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m overwrite_cache \u001b[38;5;129;01mand\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m cache_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(cache_path): \u001b[38;5;66;03m# remove old cache\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/elk-experiments/cupbearer/src/cupbearer/scripts/train_detector.py:18\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(task, detector, save_path, eval_batch_size, **train_kwargs)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m(\n\u001b[1;32m     10\u001b[0m     task: Task,\n\u001b[1;32m     11\u001b[0m     detector: AnomalyDetector,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrain_kwargs,\n\u001b[1;32m     15\u001b[0m ):\n\u001b[1;32m     16\u001b[0m     detector\u001b[38;5;241m.\u001b[39mset_model(task\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[0;32m---> 18\u001b[0m     \u001b[43mdetector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrusted_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrusted_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43muntrusted_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muntrusted_train_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrain_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m save_path:\n\u001b[1;32m     25\u001b[0m         save_path \u001b[38;5;241m=\u001b[39m Path(save_path)\n",
      "File \u001b[0;32m~/projects/elk-experiments/cupbearer/src/cupbearer/detectors/statistical/statistical.py:147\u001b[0m, in \u001b[0;36mActivationCovarianceBasedDetector.train\u001b[0;34m(self, trusted_data, untrusted_data, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m, trusted_data, untrusted_data, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 147\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrusted_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrusted_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muntrusted_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muntrusted_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentering post processing\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# Post process\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/elk-experiments/cupbearer/src/cupbearer/detectors/statistical/statistical.py:67\u001b[0m, in \u001b[0;36mStatisticalDetector.train\u001b[0;34m(self, trusted_data, untrusted_data, batch_size, pbar, max_steps, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_steps \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m max_steps:\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m activations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_activations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_update(activations)\n",
      "File \u001b[0;32m~/projects/elk-experiments/cupbearer/src/cupbearer/detectors/activation_based.py:215\u001b[0m, in \u001b[0;36mActivationBasedDetector.get_activations\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    212\u001b[0m inputs \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39minputs_from_batch(batch)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_activations_no_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache\u001b[38;5;241m.\u001b[39mget_activations(\n\u001b[1;32m    218\u001b[0m     inputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_names, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_activations_no_cache\n\u001b[1;32m    219\u001b[0m )\n",
      "File \u001b[0;32m~/projects/elk-experiments/elk_experiments/eap_detector.py:146\u001b[0m, in \u001b[0;36mEAPDetector._get_activations_no_cache\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39madd_hook(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownstream_hook_filter, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclean_downstream_hook_fn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbwd\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    145\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meffect_prob_func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(model_input, return_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m\"\u001b[39m), inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 146\u001b[0m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupstream_activations_difference \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/elk-experiments-AZ2LBS3Q-py3.10/lib/python3.10/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/elk-experiments-AZ2LBS3Q-py3.10/lib/python3.10/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/elk-experiments-AZ2LBS3Q-py3.10/lib/python3.10/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_detector_cache(\n",
    "    detector_dir=detector_dir,\n",
    "    detector=detector,\n",
    "    task=task,\n",
    "    batch_size=64,\n",
    "    eval_batch_size=64,\n",
    "    cache=None,\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trusted_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check detector scores varying on batch size\n",
    "scores_batch = detector.scores(trusted_tokens[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_single = [detector.scores(trusted_tokens[i].unsqueeze(0)) for i in range(5)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eap_scores_batch = detector.get_activations(trusted_tokens[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eap_scores_single = [detector.get_activations(trusted_tokens[i].unsqueeze(0)) for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eap_scores_single_reverse = [detector.get_activations(trusted_tokens[5-i-1].unsqueeze(0)) for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eap_scores_batch[\"eap_scores\"][0].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.abs(eap_scores_batch[\"eap_scores\"][0].flatten() - eap_scores_single[0][\"eap_scores\"].flatten()).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.where(torch.abs(eap_scores_batch[\"eap_scores\"][0].flatten() - eap_scores_single[0][\"eap_scores\"].flatten()) > 1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_single, scores_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pos Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_edge_names = [(edge[0], edge[1]) for edge in clean_edges]\n",
    "len(clean_edge_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_dir = graph_dir / \"clean_edges\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = EAPMahalanobisDetector(\n",
    "    effect_prob_func=partial(effect_prob_func, effect_tokens=effect_tokens),\n",
    "    upstream_nodes=[\"head\"],\n",
    "    downstream_nodes=[\"head\"],\n",
    "    edge_filter=partial(edge_set_filter, edge_set=clean_edge_names),\n",
    "    layer_aggregation=\"mean\", \n",
    "    cache=None, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_detector_cache(\n",
    "    detector_dir, \n",
    "    detector, \n",
    "    small_task, \n",
    "    batch_size=64, \n",
    "    eval_batch_size=64, \n",
    "    cache=None, \n",
    "    cache_path=None,\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abs Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_graph.show(threshold=threshold, abs_scores=True, fdir=graph_dir, fname=\"clean_graph_abs.png\")\n",
    "display(Image(graph_dir / \"clean_graph_abs.png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_abs_edges = clean_graph.top_edges(threshold=threshold, abs_scores=True)\n",
    "clean_abs_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_abs_edge_names = [(edge[0], edge[1]) for edge in clean_abs_edges]\n",
    "len(clean_abs_edge_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_dir = graph_dir / \"clean_abs_edges\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = EAPMahalanobisDetector(\n",
    "    effect_prob_func=partial(effect_prob_func, effect_tokens=effect_tokens),\n",
    "    upstream_nodes=[\"head\"],\n",
    "    downstream_nodes=[\"head\"],\n",
    "    edge_filter=partial(edge_set_filter, edge_set=clean_abs_edge_names),\n",
    "    layer_aggregation=\"mean\", \n",
    "    cache=None, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_detector_cache(\n",
    "    detector_dir, \n",
    "    detector, \n",
    "    small_task, \n",
    "    batch_size=64, \n",
    "    eval_batch_size=64, \n",
    "    cache=None, \n",
    "    cache_path=None,\n",
    "    overwrite=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Full Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_abs_edges = full_graph.top_edges(threshold=threshold, abs_scores=True)\n",
    "len(full_abs_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_abs_edges_names = [(edge[0], edge[1]) for edge in full_abs_edges]\n",
    "len(full_abs_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_dir = graph_dir / \"full_abs_edges\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = EAPMahalanobisDetector(\n",
    "    effect_prob_func=partial(effect_prob_func, effect_tokens=effect_tokens),\n",
    "    upstream_nodes=nodes,\n",
    "    downstream_nodes=nodes,\n",
    "    edge_filter=partial(edge_set_filter, edge_set=full_abs_edges_names),\n",
    "    layer_aggregation=\"mean\", \n",
    "    cache=None, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_detector_cache(\n",
    "    detector_dir, \n",
    "    detector, \n",
    "    small_task, \n",
    "    batch_size=128, \n",
    "    eval_batch_size=128, \n",
    "    cache=None, \n",
    "    cache_path=None,\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector.load_weights(detector_dir / \"detector.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import defaultdict\n",
    "from loguru import logger\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = small_task.test_data\n",
    "batch_size: int = 128\n",
    "histogram_percentile: float = 95\n",
    "save_path: Path | str | None = None\n",
    "num_bins: int = 100\n",
    "pbar: bool = True\n",
    "layerwise: bool = False\n",
    "log_yaxis: bool = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector.set_model(small_task.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    # For some methods, such as adversarial abstractions, it might matter how\n",
    "    # normal/anomalous data is distributed into batches. In that case, we want\n",
    "    # to mix them by default.\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "metrics = defaultdict(dict)\n",
    "assert 0 < histogram_percentile <= 100\n",
    "\n",
    "if pbar:\n",
    "    test_loader = tqdm(test_loader, desc=\"Evaluating\", leave=False)\n",
    "\n",
    "scores = defaultdict(list)\n",
    "labels = defaultdict(list)\n",
    "\n",
    "# It's important we don't use torch.inference_mode() here, since we want\n",
    "# to be able to override this in certain detectors using torch.enable_grad().\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        inputs, new_labels = batch\n",
    "        if layerwise:\n",
    "            new_scores = detector.layerwise_scores(inputs)\n",
    "        else:\n",
    "            new_scores = {\"all\": detector.scores(inputs)}\n",
    "        for layer, score in new_scores.items():\n",
    "            if isinstance(score, torch.Tensor):\n",
    "                score = score.cpu().numpy()\n",
    "            assert score.shape == new_labels.shape\n",
    "            scores[layer].append(score)\n",
    "            labels[layer].append(new_labels)\n",
    "scores = {layer: np.concatenate(scores[layer]) for layer in scores}\n",
    "labels = {layer: np.concatenate(labels[layer]) for layer in labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_lim = np.percentile(scores[layer], histogram_percentile).item()\n",
    "# Usually there aren't extremely low outliers, so we just use the minimum,\n",
    "# otherwise this tends to weirdly cut of the histogram.\n",
    "lower_lim = scores[layer].min().item()\n",
    "\n",
    "bins = np.linspace(lower_lim, upper_lim, num_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_lim = np.percentile(scores[layer], 100).item()\n",
    "upper_lim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_percentile = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs = {}\n",
    "\n",
    "for layer in scores:\n",
    "    auc_roc = sklearn.metrics.roc_auc_score(\n",
    "        y_true=labels[layer],\n",
    "        y_score=scores[layer],\n",
    "    )\n",
    "    ap = sklearn.metrics.average_precision_score(\n",
    "        y_true=labels[layer],\n",
    "        y_score=scores[layer],\n",
    "    )\n",
    "    logger.info(f\"AUC_ROC ({layer}): {auc_roc:.4f}\")\n",
    "    logger.info(f\"AP ({layer}): {ap:.4f}\")\n",
    "    metrics[layer][\"AUC_ROC\"] = auc_roc\n",
    "    metrics[layer][\"AP\"] = ap\n",
    "\n",
    "    upper_lim = np.percentile(scores[layer], histogram_percentile).item()\n",
    "    # Usually there aren't extremely low outliers, so we just use the minimum,\n",
    "    # otherwise this tends to weirdly cut of the histogram.\n",
    "    lower_lim = scores[layer].min().item()\n",
    "\n",
    "    bins = np.linspace(lower_lim, upper_lim, num_bins)\n",
    "\n",
    "    # Visualizations for anomaly scores\n",
    "    fig, ax = plt.subplots()\n",
    "    for i, name in enumerate([\"Normal\", \"Anomalous\"]):\n",
    "        vals = scores[layer][labels[layer] == i]\n",
    "        ax.hist(\n",
    "            vals,\n",
    "            bins=bins,\n",
    "            alpha=0.5,\n",
    "            label=name,\n",
    "            log=log_yaxis,\n",
    "        )\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(\"Anomaly score\")\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "    ax.set_title(f\"Anomaly score distribution ({layer})\")\n",
    "    textstr = f\"AUROC: {auc_roc:.1%}\\n AP: {ap:.1%}\"\n",
    "    props = dict(boxstyle=\"round\", facecolor=\"white\")\n",
    "    ax.text(\n",
    "        0.98,\n",
    "        0.80,\n",
    "        textstr,\n",
    "        transform=ax.transAxes,\n",
    "        fontsize=10,\n",
    "        verticalalignment=\"top\",\n",
    "        horizontalalignment=\"right\",\n",
    "        bbox=props,\n",
    "    )\n",
    "    figs[layer] = fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_detector_cache(\n",
    "    detector_dir, \n",
    "    detector, \n",
    "    small_task, \n",
    "    batch_size=128, \n",
    "    eval_batch_size=128, \n",
    "    cache=None, \n",
    "    cache_path=None,\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for hash tags in training set\n",
    "decoded_train_set = [small_task.model.tokenizer.decode(x[\"prefix_tokens\"]) for x in small_task.trusted_data.data]\n",
    "decoded_clean_untrusted = [small_task.model.tokenizer.decode(x[\"prefix_tokens\"]) for x in small_task.test_data.normal_data.data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_hash_train = [x for x in decoded_train_set if \"#\" in x]\n",
    "has_hash_clean_untrusted = [x for x in decoded_clean_untrusted if \"#\" in x]\n",
    "len(has_hash_train), len(has_hash_clean_untrusted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_hash_clean_untrusted_idxs = [i for i, x in enumerate(decoded_clean_untrusted) if \"#\" in x]\n",
    "has_hash_clean_untrusted_tokens = untrusted_clean_tokens[has_hash_clean_untrusted_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untrusted_clean_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_hash_clean_untrusted_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector.set_model(small_task.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.model(has_hash_clean_untrusted_tokens)[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.model(has_hash_clean_untrusted_tokens[1].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(hex_scores) / len(hex_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hex_acts = detector.get_activations(has_hash_clean_untrusted_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_act = detector.get_activations(has_hash_clean_untrusted_tokens[1].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_act[\"eap_scores\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hex_acts[\"eap_scores\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hex_scores = detector.scores(has_hash_clean_untrusted_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_scores = scores[\"all\"][labels[\"all\"] == 0]\n",
    "anomalous_scores = scores[\"all\"][labels[\"all\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(clean_scores), np.median(anomalous_scores), np.mean(clean_scores), np.mean(anomalous_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(clean_scores)[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_hash_clean_untrusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_task_no_hash = get_task_subset(task, 2048, 1024, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(small_task_no_hash.test_data.normal_data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_task_no_hash.test_data.normal_data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_test_data = [x for x in small_task_no_hash.test_data.normal_data.data if \"#\" not in small_task_no_hash.model.tokenizer.decode(x[\"prefix_tokens\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cupbearer.data import MixedData\n",
    "from cupbearer.tasks.tiny_natural_mechanisms import TinyNaturalMechanismsDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = MixedData(TinyNaturalMechanismsDataset(filtered_test_data), small_task_no_hash.test_data.anomalous_data, return_anomaly_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_task_no_hash.test_data = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_left_over = len(small_task_no_hash.test_data.normal_data.data) % 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_task_no_hash.test_data.normal_data.data = small_task_no_hash.test_data.normal_data.data[:-num_left_over]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: figure out what's going on here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval on untrusted data without hash tags\n",
    "scripts.eval_detector(\n",
    "    small_task_no_hash,\n",
    "    detector,\n",
    "    save_path=Path(str(detector_dir) + \"_no_hash\"),\n",
    "    pbar=True, \n",
    "    batch_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Detector by Edge Difference Between Untrusted and Trusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trusted_edge_names = [edge[:2] for edge in clean_edges]\n",
    "untrusted_edge_names = [edge[:2] for edge in untrusted_edges]\n",
    "edge_diff = set(untrusted_edge_names) - set(trusted_edge_names)\n",
    "len(edge_diff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_dir = out_dir / \"pythia-70m-hex-small-untrusted_diff\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = ActivationCache(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = EAPMahalanobisDetector(\n",
    "    effect_prob_func=partial(effect_prob_func, effect_tokens=effect_tokens),\n",
    "    upstream_nodes=[\"head\"],\n",
    "    downstream_nodes=[\"head\"],\n",
    "    edge_filter=partial(edge_set_filter, edge_set=edge_diff),\n",
    "    seq_len=16,\n",
    "    layer_aggregation=\"mean\", \n",
    "    cache=cache\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_detector_cache(\n",
    "    detector_dir, detector, small_task, batch_size=128, eval_batch_size=128, cache=cache, \n",
    "    cache_path=None, overwrite=True, overwrite_cache=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector.means[\"eap_scores\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector.covariances[\"eap_scores\"].diag()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Getting Top Edges across Entire Distribution, filtering anomolies with respect to that"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elk-experiments-AZ2LBS3Q-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
