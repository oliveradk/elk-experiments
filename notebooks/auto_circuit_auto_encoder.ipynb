{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set cuda visible devices\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from auto_circuit.types import AblationType\n",
    "from auto_circuit.utils.graph_utils import patchable_model, set_mask_batch_size, train_mask_mode\n",
    "from auto_circuit.model_utils.sparse_autoencoders.autoencoder_transformer import (\n",
    "    sae_model, \n",
    "    AutoencoderTransformer\n",
    ")\n",
    "\n",
    "from cupbearer import tasks, scripts, utils\n",
    "from cupbearer.tasks.tiny_natural_mechanisms import get_effect_tokens \n",
    "from cupbearer.detectors.extractors.eap_extractor import EAPFeatureExtractor, set_model\n",
    "\n",
    "from elk_experiments.tiny_natural_mechanisms_utils import get_task_subset\n",
    "from elk_experiments.auto_circuit_utils import make_prompt_data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "202541bbf54d4eab8e3ed0a51f43d3d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(config.json:   0%|          | 0.00/567 [00:00<?, ?B/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f1d105583bd44d4a8dafc932af97740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(model.safetensors:   0%|          | 0.00/166M [00:00<?, ?B/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8357957915ce4dfe9180b95dffbc2a59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(tokenizer_config.json:   0%|          | 0.00/396 [00:00<?, ?B/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "055c31b03d8547b480316209bf56b979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "666c5831eb8f4035befd646ef44e1068",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model pythia-70m-deduped into HookedTransformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://baulab.us/u/smarks/autoencoders/pythia-70m-deduped/mlp_out_layer0/0_8192/ae.pt\" to /nas/ucb/oliveradk/elk-experiments/auto-circuit/.autoencoder_cache/pythia-70m-deduped_layer_0_0_8192.pt\n",
      "100%|██████████| 32.0M/32.0M [00:07<00:00, 4.38MB/s]\n",
      "Downloading: \"https://baulab.us/u/smarks/autoencoders/pythia-70m-deduped/mlp_out_layer1/0_8192/ae.pt\" to /nas/ucb/oliveradk/elk-experiments/auto-circuit/.autoencoder_cache/pythia-70m-deduped_layer_1_0_8192.pt\n",
      "100%|██████████| 32.0M/32.0M [00:02<00:00, 13.7MB/s]\n",
      "Downloading: \"https://baulab.us/u/smarks/autoencoders/pythia-70m-deduped/mlp_out_layer2/0_8192/ae.pt\" to /nas/ucb/oliveradk/elk-experiments/auto-circuit/.autoencoder_cache/pythia-70m-deduped_layer_2_0_8192.pt\n",
      "100%|██████████| 32.0M/32.0M [00:02<00:00, 13.4MB/s]\n",
      "Downloading: \"https://baulab.us/u/smarks/autoencoders/pythia-70m-deduped/mlp_out_layer3/0_8192/ae.pt\" to /nas/ucb/oliveradk/elk-experiments/auto-circuit/.autoencoder_cache/pythia-70m-deduped_layer_3_0_8192.pt\n",
      "100%|██████████| 32.0M/32.0M [00:03<00:00, 9.06MB/s]\n",
      "Downloading: \"https://baulab.us/u/smarks/autoencoders/pythia-70m-deduped/mlp_out_layer4/0_8192/ae.pt\" to /nas/ucb/oliveradk/elk-experiments/auto-circuit/.autoencoder_cache/pythia-70m-deduped_layer_4_0_8192.pt\n",
      "100%|██████████| 32.0M/32.0M [00:02<00:00, 16.0MB/s]\n",
      "Downloading: \"https://baulab.us/u/smarks/autoencoders/pythia-70m-deduped/mlp_out_layer5/0_8192/ae.pt\" to /nas/ucb/oliveradk/elk-experiments/auto-circuit/.autoencoder_cache/pythia-70m-deduped_layer_5_0_8192.pt\n",
      "100%|██████████| 32.0M/32.0M [00:09<00:00, 3.66MB/s]\n"
     ]
    }
   ],
   "source": [
    "# hmm probably want to to thresholding before trying anomaly detection\n",
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "model_name = \"pythia-70m-deduped\"\n",
    "device = \"cuda\"\n",
    "task_name = \"ifelse\"\n",
    "\n",
    "autoencoder_input = \"resid_delta_mlp\"\n",
    "pythia_size = \"0_8192\"\n",
    "\n",
    "task = get_task_subset(tasks.tiny_natural_mechanisms(task_name, device, model_name), 64, 32, 32)\n",
    "\n",
    "base_model: HookedTransformer = task.model\n",
    "\n",
    "base_model.set_use_attn_result(True)\n",
    "base_model.set_use_attn_in(True)\n",
    "base_model.set_use_split_qkv_input(True)\n",
    "base_model.set_use_hook_mlp_in(True)\n",
    "\n",
    "base_model.cfg.use_attn_result = True\n",
    "base_model.cfg.use_attn_in = True\n",
    "base_model.cfg.use_split_qkv_input = True\n",
    "base_model.cfg.use_hook_mlp_in = True\n",
    "base_model.eval()\n",
    "\n",
    "ac_base_model = patchable_model(\n",
    "    base_model, \n",
    "    factorized=True,\n",
    "    slice_output=\"last_seq\",\n",
    "    separate_qkv=True\n",
    ")\n",
    "\n",
    "model = sae_model(\n",
    "    base_model,\n",
    "    autoencoder_input,\n",
    "    load_pretrained=True,\n",
    "    pythia_size=pythia_size,\n",
    "    new_instance=True\n",
    ")\n",
    "\n",
    "ac_model = patchable_model(\n",
    "    model,\n",
    "    factorized=True,\n",
    "    slice_output=\"last_seq\",\n",
    "    separate_qkv=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3580, 3124351, 872.7237430167597)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac_base_model.n_edges, ac_model.n_edges, ac_model.n_edges / ac_base_model.n_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = ac_model(task.trusted_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running dataset for autoencoder pruning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0882ce0e0ce428fbd20d497defb5b5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(          | 0/? [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1ed367b2d8b45bd9bb6e8ac58fea8bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(          | 0/? [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Autoencoder activated latent counts: [5045, 5827, 3473, 4149, 5917, 4755]\n",
      "Autoencoder latent counts: [1000, 1000, 1000, 1000, 1000, 1000]\n",
      "Pruned vs. Unpruned KL Div: 0.15515241026878357\n"
     ]
    }
   ],
   "source": [
    "# from copy import deepcopy\n",
    "# effect_tokens= get_effect_tokens(task_name, task.model)\n",
    "# train_loader = make_prompt_data_loader(task.trusted_data, effect_tokens, task.model, 32)\n",
    "# pruned_model = deepcopy(model)\n",
    "# pruned_model._prune_latents_with_dataset(\n",
    "#     dataloader=train_loader,\n",
    "#     max_latents=1000, \n",
    "#     include_corrupt=False, \n",
    "#     seq_len=None\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_pruned_model = patchable_model(\n",
    "    pruned_model,\n",
    "    factorized=True,\n",
    "    slice_output=\"last_seq\",\n",
    "    separate_qkv=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3580, 384199, 107.318156424581)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac_base_model.n_edges, ac_pruned_model.n_edges, ac_pruned_model.n_edges / ac_base_model.n_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge Attribution Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model attn-only-1l into HookedTransformer\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model pythia-70m-deduped into HookedTransformer\n",
      "Moving model to device:  cpu\n"
     ]
    }
   ],
   "source": [
    "task_name = \"ifelse\"\n",
    "model_name = \"pythia-70m-deduped\"\n",
    "device = \"cpu\"\n",
    "\n",
    "task = get_task_subset(tasks.tiny_natural_mechanisms(task_name, device, model_name), 64, 32, 32)\n",
    "\n",
    "task.model.cfg.use_attn_result = True\n",
    "task.model.cfg.use_attn_in = True\n",
    "task.model.cfg.use_split_qkv_input = True\n",
    "task.model.cfg.use_hook_mlp_in = True\n",
    "task.model.eval()\n",
    "\n",
    "\n",
    "# default_model = HookedTransformer.from_pretrained(\"pythia-70m-deduped\")\n",
    "layer_idx = 3\n",
    "autoencoder_input = \"resid_delta_mlp\"\n",
    "pythia_size = \"0_8192\"\n",
    "\n",
    "\n",
    "task.model = sae_model(\n",
    "    task.model,\n",
    "    autoencoder_input,\n",
    "    load_pretrained=True,\n",
    "    pythia_size=pythia_size,\n",
    "    new_instance=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 16])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader)).clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running dataset for autoencoder pruning...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0561381fd444a87a16f49da34dbc7d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(          | 0/? [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff3943838cd454faa0aff6004afd4bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(          | 0/? [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Autoencoder activated latent counts: [5046, 5827, 3473, 4149, 5917, 4755]\n",
      "Autoencoder latent counts: [5046, 5046, 3473, 4149, 5046, 4755]\n",
      "Pruned vs. Unpruned KL Div: 5.016931754653342e-05\n"
     ]
    }
   ],
   "source": [
    "# prune latents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "eap_feature_extractor = EAPFeatureExtractor(\n",
    "    effect_tokens=get_effect_tokens(task_name, task.model),\n",
    "    model=task.model,\n",
    "    grad_function=\"prob\",\n",
    "    answer_function=\"avg_val\",\n",
    "    ablation_type=AblationType.ZERO,\n",
    "    abs_value=True,\n",
    "    integrated_grad_samples=None,\n",
    "    resid_src=True,\n",
    "    resid_dest=True,\n",
    "    attn=True,\n",
    "    mlp=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10109])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(eap_feature_extractor.model.patch_masks.values())).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43meap_feature_extractor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclean\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/elk-experiments-AZ2LBS3Q-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/elk-experiments-AZ2LBS3Q-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/elk-experiments/auto-circuit/auto_circuit/utils/patchable_model.py:139\u001b[0m, in \u001b[0;36mPatchableModel.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03mWrapper around the forward method of the wrapped model. If `kv_caches` is not\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m`None`, the KV cache is passed to the wrapped model as a keyword argument.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkv_caches \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_kv_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrapped_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    141\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/elk-experiments-AZ2LBS3Q-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/elk-experiments-AZ2LBS3Q-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/elk-experiments/auto-circuit/auto_circuit/model_utils/sparse_autoencoders/autoencoder_transformer.py:36\u001b[0m, in \u001b[0;36mAutoencoderTransformer.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrapped_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/elk-experiments-AZ2LBS3Q-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/elk-experiments-AZ2LBS3Q-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/elk-experiments/TransformerLens/transformer_lens/HookedTransformer.py:550\u001b[0m, in \u001b[0;36mHookedTransformer.forward\u001b[0;34m(self, input, return_type, loss_per_token, prepend_bos, padding_side, start_at_layer, tokens, shortformer_pos_embed, attention_mask, stop_at_layer, past_kv_cache)\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shortformer_pos_embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    546\u001b[0m         shortformer_pos_embed \u001b[38;5;241m=\u001b[39m shortformer_pos_embed\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m    547\u001b[0m             devices\u001b[38;5;241m.\u001b[39mget_device_for_block_index(i, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg)\n\u001b[1;32m    548\u001b[0m         )\n\u001b[0;32m--> 550\u001b[0m     residual \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Cache contains a list of HookedTransformerKeyValueCache objects, one for each\u001b[39;49;00m\n\u001b[1;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# block\u001b[39;49;00m\n\u001b[1;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stop_at_layer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;66;03m# When we stop at an early layer, we end here rather than doing further computation\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m residual\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/elk-experiments-AZ2LBS3Q-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/elk-experiments-AZ2LBS3Q-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/elk-experiments/TransformerLens/transformer_lens/components/transformer_block.py:189\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, resid_pre, shortformer_pos_embed, past_kv_cache_entry, attention_mask)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mparallel_attn_mlp:\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# Dumb thing done by GPT-J, both MLP and Attn read from resid_pre and write to resid_post, no resid_mid used.\u001b[39;00m\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;66;03m# In GPT-J, LN1 and LN2 are tied, in GPT-NeoX they aren't.\u001b[39;00m\n\u001b[1;32m    186\u001b[0m     normalized_resid_pre_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln2(\n\u001b[1;32m    187\u001b[0m         resid_pre \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39muse_hook_mlp_in \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_mlp_in(resid_pre\u001b[38;5;241m.\u001b[39mclone())\n\u001b[1;32m    188\u001b[0m     )\n\u001b[0;32m--> 189\u001b[0m     mlp_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_mlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormalized_resid_pre_2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m     resid_post \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_resid_post(\n\u001b[1;32m    191\u001b[0m         resid_pre \u001b[38;5;241m+\u001b[39m attn_out \u001b[38;5;241m+\u001b[39m mlp_out\n\u001b[1;32m    192\u001b[0m     )  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/projects/elk-experiments/TransformerLens/transformer_lens/components/transformer_block.py:208\u001b[0m, in \u001b[0;36mTransformerBlock.apply_mlp\u001b[0;34m(self, normalized_resid)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39muse_normalization_before_and_after:\n\u001b[1;32m    207\u001b[0m     mlp_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln2_post(mlp_out)\n\u001b[0;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhook_mlp_out\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmlp_out\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/elk-experiments-AZ2LBS3Q-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/elk-experiments-AZ2LBS3Q-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/elk-experiments/auto-circuit/auto_circuit/model_utils/sparse_autoencoders/sparse_autoencoder.py:115\u001b[0m, in \u001b[0;36mSparseAutoencoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    113\u001b[0m latents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode(x)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatent_total_act \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m latents\u001b[38;5;241m.\u001b[39msum_to_size(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatent_total_act\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m--> 115\u001b[0m recons \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m recons\n",
      "File \u001b[0;32m~/projects/elk-experiments/auto-circuit/auto_circuit/model_utils/sparse_autoencoders/sparse_autoencoder.py:104\u001b[0m, in \u001b[0;36mSparseAutoencoder.decode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m:param x: autoencoder x (shape: [..., [seq], n_latents])\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m:return: reconstructed data (shape: [..., [seq], n_inputs])\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    103\u001b[0m ein_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m... l, ... d l -> ... l d\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 104\u001b[0m latent_outs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlatent_outs\u001b[49m\u001b[43m(\u001b[49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mein_str\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m latent_outs\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/elk-experiments-AZ2LBS3Q-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/elk-experiments-AZ2LBS3Q-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/elk-experiments/auto-circuit/auto_circuit/utils/patch_wrapper.py:126\u001b[0m, in \u001b[0;36mPatchWrapperImpl.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 126\u001b[0m     arg_0: t\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_dest:\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_src_outs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurr_src_outs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "eap_feature_extractor.model(next(iter(train_loader)).clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "eap_feature_extractor.compute_patch_out(task.trusted_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train detector\n",
    "from cupbearer.detectors.statistical import MahalanobisDetector\n",
    "detector = MahalanobisDetector(\n",
    "    feature_extractor=eap_feature_extractor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-07-18 21:23:54.720\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcupbearer.detectors.statistical.statistical\u001b[0m:\u001b[36m_train\u001b[0m:\u001b[36m53\u001b[0m - \u001b[34m\u001b[1mCollecting statistics on trusted data\u001b[0m\n",
      "\u001b[32m2024-07-18 21:23:55.914\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcupbearer.detectors.statistical.statistical\u001b[0m:\u001b[36minit_variables\u001b[0m:\u001b[36m95\u001b[0m - \u001b[34m\u001b[1mActivation sizes: \n",
      "eap_scores: torch.Size([2880])\u001b[0m\n",
      "  0%|          | 0/64 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|██████████| 64/64 [01:03<00:00,  1.01it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b8eeffd32f0492bbe8dcf4d569cad3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Evaluating:   0%|          | 0/64 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-07-18 21:26:06.781\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcupbearer.detectors.anomaly_detector\u001b[0m:\u001b[36mget_eval_results\u001b[0m:\u001b[36m343\u001b[0m - \u001b[1mAUC_ROC (all): 0.6744\u001b[0m\n",
      "\u001b[32m2024-07-18 21:26:06.782\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcupbearer.detectors.anomaly_detector\u001b[0m:\u001b[36mget_eval_results\u001b[0m:\u001b[36m344\u001b[0m - \u001b[1mAP (all): 0.6541\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(defaultdict(dict,\n",
       "             {'all': {'AUC_ROC': 0.6744060516357422,\n",
       "               'AP': 0.6540885437001855}}),\n",
       " {'all': <Figure size 640x480 with 1 Axes>})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bs = 32\n",
    "scripts.train_detector(\n",
    "    task, detector, save_path=None,eval_batch_size=bs\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elk-experiments-AZ2LBS3Q-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
