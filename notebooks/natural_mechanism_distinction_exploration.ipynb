{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "# set environment variable PYTORCH_ENABLE_MPS_FALLBACK=1\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model pythia-70m into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "# download pythia-70m from transformer lens\n",
    "import transformer_lens\n",
    "\n",
    "model = transformer_lens.HookedTransformer.from_pretrained(\"pythia-70m\")\n",
    "\n",
    "# model.generate(\"Hello, \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 11.50it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Mary went to the store with John. John gave the bag to ________'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate(\"Mary went to the store with John. John gave the bag to \", max_new_tokens=1, use_past_kv_cache=False, prepend_bos=False, do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model.run_with_cache(\"Mary went to the store with John. John gave the bag to \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9.4306], device='mps:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[0][:,-1, model.tokenizer.encode(\"Mary\")[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort logits, get index of Mary\n",
    "ordered_indicies = logits[0][:,-1].sort(descending=True).indices\n",
    "(ordered_indicies[0] == model.tokenizer.encode(\"Mary\")[0]).nonzero().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_order(model, logits, token):\n",
    "    ordered_indicies = logits[0][:,-1].sort(descending=True).indices\n",
    "    return (ordered_indicies[0] == model.tokenizer.encode(token)[0]).nonzero().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix = \"Alice uses they/\"\n",
    "logits = model.run_with_cache(prefix)\n",
    "get_token_order(model, logits, \"them\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "702"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix = \"Find the lost keys and return \"\n",
    "logits = model.run_with_cache(prefix)\n",
    "get_token_order(model, logits, \"them\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cupbearer import tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model attn-only-1l into HookedTransformer\n",
      "Moving model to device:  mps\n"
     ]
    }
   ],
   "source": [
    "task = tasks.tiny_natural_mechanisms(\"hex\", \"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prefix_and_completion(x):\n",
    "    prefix = task.model.tokenizer.decode(x[\"prefix_tokens\"])\n",
    "    completion = task.model.tokenizer.decode(x[\"completion_token\"])\n",
    "    return prefix, completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('d9b0-bd81-4108-be7', '4')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hex_prefix, hex_completion = get_prefix_and_completion(task.trusted_data.data[0])\n",
    "hex_prefix, hex_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix = hex_prefix\n",
    "logits = model.run_with_cache(prefix)\n",
    "get_token_order(model, logits, \"4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   66,    64,    65,    67,    69,    68, 18213,  7252, 21101, 19881,\n",
       "        11848,  9945,  1350, 16072, 13331, 15630, 12993, 17896,   535,   487,\n",
       "         1860, 16344, 21855,  6814,  6888,  3609, 17457,  7568,   330,   721,\n",
       "         5036,   324,  1878,  7012,  2934,   344,   891,  2718,  1765,  2548,\n",
       "         2414,  2670,   276,  2682,  1157,  3682,  2598,  2920,  2481,  3559,\n",
       "         3132,  1453,  1731,  2791,    18,  1828,  1129,  3901,    17,  3510,\n",
       "           16,   397,  2075, 10210,  2624,  2327,  3388,  1433,  1954,  1558,\n",
       "         1507,  3134,  3459, 14822,  1983,  2623,  2857,  1314,  2091,    19,\n",
       "         3104,  2078,  1415,  2231,  2001,  1959,    24,  2780,  1065,  8635,\n",
       "         1485,  2079,  2996,    23,    21,  1821,    22,   940,  1899,  1238],\n",
       "       device='mps:0')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[0][:,-1].topk(100).indices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c \n",
      "a \n",
      "b \n",
      "d \n",
      "f \n",
      "e \n",
      "ea \n",
      "aa \n",
      "cb \n",
      "bf \n"
     ]
    }
   ],
   "source": [
    "for index in logits[0][:,-1].topk(10).indices[0]:\n",
    "    print(model.tokenizer.decode(index) + \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = task.model.run_with_cache(prefix)\n",
    "get_token_order(task.model, logits, \"4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model attn-only-1l into HookedTransformer\n",
      "Moving model to device:  mps\n"
     ]
    }
   ],
   "source": [
    "from cupbearer.tasks import Task\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "\n",
    "import torch \n",
    "import blobfile as bf\n",
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "device=\"mps\"\n",
    "name = \"hex\"\n",
    "\n",
    "class TinyNaturalMechanismsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data: list[dict[str, Any]]):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Convert the list to a tensor to make sure that pytorch's default collate_fn\n",
    "        # batches the lists into a single tensor (TransformerLens requires that).\n",
    "        # Note that all sequences have the same length in these datasets.\n",
    "        return (\n",
    "            torch.tensor(self.data[idx][\"prefix_tokens\"], dtype=torch.long),\n",
    "            self.data[idx][\"completion_token\"],\n",
    "        )\n",
    "\n",
    "\n",
    "# This seems to be necessary to access the public GCS files below without logging in\n",
    "os.environ[\"NO_GCE_CHECK\"] = \"true\"\n",
    "\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    \"attn-only-1l\",\n",
    "    fold_ln=False,\n",
    "    center_writing_weights=False,\n",
    "    center_unembed=False,\n",
    "    fold_value_biases=False,\n",
    ").to(device)\n",
    "\n",
    "# Downloading the models from GCS can take ~10 seconds, so we cache them locally.\n",
    "cache_dir = Path(\".cupbearer_cache/tiny_natural_mechanisms/\")\n",
    "cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "cache_path = cache_dir / \"main.pth\"\n",
    "\n",
    "if cache_path.exists():\n",
    "    state_dict = torch.load(cache_path, map_location=device)\n",
    "else:\n",
    "    # `model_path` seems to have a typo, uses a `.path` extension instead of `.pth`\n",
    "    # with bf.BlobFile(task_data[\"model_path\"], \"rb\") as fh:\n",
    "    with bf.BlobFile(\"gs://arc-ml-public/distinctions/models/main.pth\", \"rb\") as fh:\n",
    "        state_dict = torch.load(fh, map_location=device)\n",
    "    state_dict[\"unembed.b_U\"] = model.unembed.b_U\n",
    "    torch.save(state_dict, cache_path)\n",
    "\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "cache_path = cache_dir / f\"{name}_task.json\"\n",
    "if cache_path.exists():\n",
    "    with cache_path.open(\"r\") as f:\n",
    "        task_data = json.load(f)\n",
    "else:\n",
    "    path = f\"gs://arc-ml-public/distinctions/datasets/{name}_task.json\"\n",
    "    with bf.BlobFile(path) as f:\n",
    "        task_data = json.load(f)\n",
    "    with cache_path.open(\"w\") as f:\n",
    "        json.dump(task_data, f)\n",
    "\n",
    "train_data = TinyNaturalMechanismsDataset(task_data[\"train\"])\n",
    "normal_test_data = TinyNaturalMechanismsDataset(task_data[\"test_non_anomalous\"])\n",
    "anomalous_test_data = TinyNaturalMechanismsDataset(task_data[\"test_anomalous\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('40cc\", \"#ff4040\", \"#40ff4', '0')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hex_prefix, hex_completion = get_prefix_and_completion(anomalous_test_data.data[0])\n",
    "hex_prefix, hex_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'40cc\", #40ff4'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hex_prefix[:7] + hex_prefix[19:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[22, 18, 549, 985, 13557, 566, 22, 18, 22, 18, 985, 13557, 22, 18, 566, 22]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in  anomalous_test_data.data][0][\"prefix_tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "13",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m prefix_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(model\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mencode(prefix))\n\u001b[1;32m      4\u001b[0m completion_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(model\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mencode(completion))\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m prefix_len \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m16\u001b[39m, prefix_len\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m completion_len \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, completion_len\n",
      "\u001b[0;31mAssertionError\u001b[0m: 13"
     ]
    }
   ],
   "source": [
    "for x in anomalous_test_data.data:\n",
    "    prefix, completion = get_prefix_and_completion(x)\n",
    "    prefix_len = len(model.tokenizer.encode(prefix))\n",
    "    completion_len = len(model.tokenizer.encode(completion))\n",
    "    assert prefix_len == 16, prefix_len\n",
    "    assert completion_len == 1, completion_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.tokenizer.encode(hex_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix = hex_prefix[:7] + hex_prefix[19:]\n",
    "logits = model.run_with_cache(prefix)\n",
    "get_token_order(model, logits, \"0\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elk-experiments-AZ2LBS3Q-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
