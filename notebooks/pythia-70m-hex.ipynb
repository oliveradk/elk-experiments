{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "# set environment variable PYTORCH_ENABLE_MPS_FALLBACK=1\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import torch \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hex Dataset with Pythia-70m tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hex dataset collects 16 token examples where, on the trusted set, the example ends in hexidecimal characters, and on the untrusted set, there are anomolous examples which end in alphanumeric preceeded by a '#' (i.e. a hex color)\n",
    "\n",
    "In the original dataset, they train a \"clean model\" which never sees hex colors, and use the clean model to determine whether hexidecimal prediction is \"caused\" by induction like mechanisms or the hex color\n",
    "\n",
    "However, we can probably get away with discarding the clean model and just treating all hex colors as anomalous (if that's too difficult , we can remove all instances where there are multiple triggers, i.e. multiple hex colors)\n",
    "\n",
    "\"trigger\" is any hexidecimal character following a '#' in the same string\n",
    "\n",
    "\"behavior\" is any hexidecimal character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: cleanup notebook, \n",
    "# add cupbearer task within notebook, \n",
    "# run malanabois on final layer final token\n",
    "# try edge attribution patching on this task (metric is probability of hexidecimal, zero ablate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliverdaniels-koch/Library/Caches/pypoetry/virtualenvs/elk-experiments-AZ2LBS3Q-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model pythia-70m into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "# download pythia-70m from transformer lens\n",
    "import transformer_lens\n",
    "\n",
    "model = transformer_lens.HookedTransformer.from_pretrained(\"pythia-70m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hex_nn.datasets import get_token_dataset\n",
    "from hex_nn.masking.behaviors import registry as behavior_registry\n",
    "from hex_nn.masking.triggers import registry as trigger_registry\n",
    "from hex_nn.masking.distinctions import get_behavior_examples\n",
    "from hex_nn.datasets import cache_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cache_json(\"distinctions/{behavior_name}_c4_{c4_n_items}_code_{code_n_items}.json\")\n",
    "def get_distinctions_dataset(\n",
    "    behavior_name, tokenizer, *, c4_n_items=7 * 2**16, code_n_items=2**16\n",
    "):\n",
    "    c4_token_dataset = get_token_dataset(\n",
    "        \"c4\", tokenizer, split=\"train_rev\", n_items=c4_n_items\n",
    "    )\n",
    "    code_token_dataset = get_token_dataset(\n",
    "        \"code\", tokenizer, split=\"train_rev\", n_items=code_n_items\n",
    "    )\n",
    "    token_dataset = c4_token_dataset + code_token_dataset\n",
    "    behavior_masker = behavior_registry[behavior_name](tokenizer)\n",
    "    trigger_masker = trigger_registry[behavior_name](tokenizer)\n",
    "    examples = get_behavior_examples(token_dataset, behavior_masker, trigger_masker)\n",
    "    # models = {\n",
    "    #     \"main\": Transformer.from_pretrained(MAIN_MODEL_PATH),\n",
    "    #     \"clean\": Transformer.from_pretrained(CLEAN_MODEL_PATHS[behavior_name]),\n",
    "    # }\n",
    "    # for model_name, model in models.items():\n",
    "    #     if th.cuda.is_available():\n",
    "    #         model = model.to(\"cuda\")\n",
    "    #     examples = add_probs(\n",
    "    #         examples,\n",
    "    #         model,\n",
    "    #         behavior_masker.effect_tokens,\n",
    "    #         input_name=\"prefix\",\n",
    "    #         model_name=model_name,\n",
    "    #     )\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cache_json(\"distinctions/{behavior_name}_task.json\")\n",
    "def get_distinctions_task(\n",
    "    behavior_name, tokenizer, *, n_train=2**14, n_anomalous=2**10, c4_n_items=7 * 2**16, \n",
    "    code_n_items=2**16\n",
    "):\n",
    "    examples = get_distinctions_dataset(behavior_name, tokenizer, c4_n_items=c4_n_items, code_n_items=code_n_items)\n",
    "    # for example in examples:\n",
    "    #     example[\"logratio\"] = np.log(\n",
    "    #         example[\"main_probs\"][-1] / example[\"clean_probs\"][-1]\n",
    "    #     )\n",
    "    # logratios = [\n",
    "    #     example[\"logratio\"] for example in examples if not example[\"triggered\"]\n",
    "    # ]\n",
    "    # lower_logratio = np.percentile(logratios, 1)\n",
    "    # upper_logratio = np.percentile(logratios, 99)\n",
    "    non_anomalous_examples = [\n",
    "        example\n",
    "        for example in examples\n",
    "        if not example[\"triggered\"]\n",
    "        # and example[\"logratio\"] >= lower_logratio\n",
    "        # and example[\"logratio\"] <= upper_logratio\n",
    "    ]\n",
    "    anomalous_examples = [\n",
    "        example\n",
    "        for example in examples\n",
    "        if example[\"triggered\"] #and example[\"logratio\"] > upper_logratio\n",
    "    ]\n",
    "    assert len(non_anomalous_examples) >= n_train + n_anomalous\n",
    "    assert len(anomalous_examples) >= n_anomalous\n",
    "\n",
    "    def to_task_example(example):\n",
    "        return {\n",
    "            \"prefix_tokens\": example[\"prefix_tokens\"],\n",
    "            \"completion_token\": example[\"completion_token\"],\n",
    "            # \"effect_prob\": example[\"main_probs\"][-1],\n",
    "            # \"clean_effect_prob\": example[\"clean_probs\"][-1],\n",
    "        }\n",
    "\n",
    "    train_examples = [\n",
    "        to_task_example(example) for example in non_anomalous_examples[:n_train]\n",
    "    ]\n",
    "    test_non_anomalous_examples = [\n",
    "        to_task_example(example)\n",
    "        for example in non_anomalous_examples[n_train : n_train + n_anomalous]\n",
    "    ]\n",
    "    test_anomalous_examples = [\n",
    "        to_task_example(example) for example in anomalous_examples[:n_anomalous]\n",
    "    ]\n",
    "    behavior_masker = behavior_registry[behavior_name](tokenizer)\n",
    "    return {\n",
    "        \"train\": train_examples,\n",
    "        \"test_non_anomalous\": test_non_anomalous_examples,\n",
    "        \"test_anomalous\": test_anomalous_examples,\n",
    "        \"cause_tokens\": sorted(behavior_masker.cause_tokens),\n",
    "        \"effect_tokens\": sorted(behavior_masker.effect_tokens),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "c4_n_items=7 * 2**16\n",
    "code_n_items=2**16\n",
    "# c4_n_items = 2**16\n",
    "# code_n_items = 2**16\n",
    "n_train=2**14 \n",
    "n_anomalous=2**10\n",
    "# n_train=2**8\n",
    "# n_anomalous=2**5\n",
    "behavior_name = \"hex\"\n",
    "tokenizer = model.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = get_distinctions_task(behavior_name, tokenizer, n_train=n_train, n_anomalous=n_anomalous, c4_n_items=c4_n_items, code_n_items=code_n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'test_non_anomalous', 'test_anomalous', 'cause_tokens', 'effect_tokens'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16384, 1024)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(task[\"train\"]), len(task[\"test_anomalous\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0123456789abcdef'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hex_chars = \"\".join(f\"{i:x}\" for i in range(16))\n",
    "hex_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cause_token in task[\"cause_tokens\"]:\n",
    "    out = tokenizer.decode([cause_token])\n",
    "    assert all([c in hex_chars for c in out if c != \" \"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for effect_token in task[\"effect_tokens\"]:\n",
    "    out = tokenizer.decode([effect_token])\n",
    "    assert all([c in hex_chars for c in out if c != \" \"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct Cupbearer Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cupbearer.tasks import Task\n",
    "from cupbearer.tasks.tiny_natural_mechanisms import TinyNaturalMechanismsDataset\n",
    "\n",
    "train_data = TinyNaturalMechanismsDataset(task[\"train\"])\n",
    "normal_test_data = TinyNaturalMechanismsDataset(task[\"test_non_anomalous\"])\n",
    "anomalous_test_data = TinyNaturalMechanismsDataset(task[\"test_anomalous\"])\n",
    "\n",
    "cp_task = Task.from_separate_data(\n",
    "    model=model, \n",
    "    trusted_data=train_data,\n",
    "    clean_test_data=normal_test_data,\n",
    "    anomalous_test_data=anomalous_test_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cupbearer import detectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run malanabois on final layer final token\n",
    "def get_activation_at_last_token(\n",
    "    activation: torch.Tensor, inputs: list[list[int]], name: str\n",
    "):\n",
    "    if activation.ndim == 3:\n",
    "        # Residual stream or equivalent, shape is (batch, seq, hidden)\n",
    "        return activation[:, -1, :]\n",
    "    elif activation.ndim == 4 and activation.shape[-1] == activation.shape[-2]:\n",
    "        # Attention, shape is (batch, num_heads, query, key)\n",
    "        # TODO: this could also be Q/K/V if n_heads happens to be head_dim\n",
    "        return activation[:, :, -1, :].reshape(activation.shape[0], -1)\n",
    "    elif activation.ndim == 4:\n",
    "        # Query/key/value, shape is (batch, seq, num_heads, hidden)\n",
    "        return activation[:, -1, :, :].reshape(activation.shape[0], -1)\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected activation shape: {activation.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "    # \"hook_embed.output\",\n",
    "    \"blocks.0.hook_attn_out.output\",\n",
    "    # \"blocks.0.attn.hook_attn_scores.output\",\n",
    "    # \"blocks.0.attn.hook_q.output\",\n",
    "    # \"ln_final.hook_normalized.output\",\n",
    "    # \"blocks.4.hook_resid_post.output\"\n",
    "    \"blocks.4.hook_attn_out.output\"\n",
    "]\n",
    "\n",
    "detector = detectors.MahalanobisDetector(\n",
    "    names, layer_aggregation=\"mean\", activation_processing_func=get_activation_at_last_token\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "embed\n",
      "hook_embed\n",
      "blocks\n",
      "blocks.0\n",
      "blocks.0.ln1\n",
      "blocks.0.ln1.hook_scale\n",
      "blocks.0.ln1.hook_normalized\n",
      "blocks.0.ln2\n",
      "blocks.0.ln2.hook_scale\n",
      "blocks.0.ln2.hook_normalized\n",
      "blocks.0.attn\n",
      "blocks.0.attn.hook_k\n",
      "blocks.0.attn.hook_q\n",
      "blocks.0.attn.hook_v\n",
      "blocks.0.attn.hook_z\n",
      "blocks.0.attn.hook_attn_scores\n",
      "blocks.0.attn.hook_pattern\n",
      "blocks.0.attn.hook_result\n",
      "blocks.0.attn.hook_rot_k\n",
      "blocks.0.attn.hook_rot_q\n",
      "blocks.0.mlp\n",
      "blocks.0.mlp.hook_pre\n",
      "blocks.0.mlp.hook_post\n",
      "blocks.0.hook_attn_in\n",
      "blocks.0.hook_q_input\n",
      "blocks.0.hook_k_input\n",
      "blocks.0.hook_v_input\n",
      "blocks.0.hook_mlp_in\n",
      "blocks.0.hook_attn_out\n",
      "blocks.0.hook_mlp_out\n",
      "blocks.0.hook_resid_pre\n",
      "blocks.0.hook_resid_post\n",
      "blocks.1\n",
      "blocks.1.ln1\n",
      "blocks.1.ln1.hook_scale\n",
      "blocks.1.ln1.hook_normalized\n",
      "blocks.1.ln2\n",
      "blocks.1.ln2.hook_scale\n",
      "blocks.1.ln2.hook_normalized\n",
      "blocks.1.attn\n",
      "blocks.1.attn.hook_k\n",
      "blocks.1.attn.hook_q\n",
      "blocks.1.attn.hook_v\n",
      "blocks.1.attn.hook_z\n",
      "blocks.1.attn.hook_attn_scores\n",
      "blocks.1.attn.hook_pattern\n",
      "blocks.1.attn.hook_result\n",
      "blocks.1.attn.hook_rot_k\n",
      "blocks.1.attn.hook_rot_q\n",
      "blocks.1.mlp\n",
      "blocks.1.mlp.hook_pre\n",
      "blocks.1.mlp.hook_post\n",
      "blocks.1.hook_attn_in\n",
      "blocks.1.hook_q_input\n",
      "blocks.1.hook_k_input\n",
      "blocks.1.hook_v_input\n",
      "blocks.1.hook_mlp_in\n",
      "blocks.1.hook_attn_out\n",
      "blocks.1.hook_mlp_out\n",
      "blocks.1.hook_resid_pre\n",
      "blocks.1.hook_resid_post\n",
      "blocks.2\n",
      "blocks.2.ln1\n",
      "blocks.2.ln1.hook_scale\n",
      "blocks.2.ln1.hook_normalized\n",
      "blocks.2.ln2\n",
      "blocks.2.ln2.hook_scale\n",
      "blocks.2.ln2.hook_normalized\n",
      "blocks.2.attn\n",
      "blocks.2.attn.hook_k\n",
      "blocks.2.attn.hook_q\n",
      "blocks.2.attn.hook_v\n",
      "blocks.2.attn.hook_z\n",
      "blocks.2.attn.hook_attn_scores\n",
      "blocks.2.attn.hook_pattern\n",
      "blocks.2.attn.hook_result\n",
      "blocks.2.attn.hook_rot_k\n",
      "blocks.2.attn.hook_rot_q\n",
      "blocks.2.mlp\n",
      "blocks.2.mlp.hook_pre\n",
      "blocks.2.mlp.hook_post\n",
      "blocks.2.hook_attn_in\n",
      "blocks.2.hook_q_input\n",
      "blocks.2.hook_k_input\n",
      "blocks.2.hook_v_input\n",
      "blocks.2.hook_mlp_in\n",
      "blocks.2.hook_attn_out\n",
      "blocks.2.hook_mlp_out\n",
      "blocks.2.hook_resid_pre\n",
      "blocks.2.hook_resid_post\n",
      "blocks.3\n",
      "blocks.3.ln1\n",
      "blocks.3.ln1.hook_scale\n",
      "blocks.3.ln1.hook_normalized\n",
      "blocks.3.ln2\n",
      "blocks.3.ln2.hook_scale\n",
      "blocks.3.ln2.hook_normalized\n",
      "blocks.3.attn\n",
      "blocks.3.attn.hook_k\n",
      "blocks.3.attn.hook_q\n",
      "blocks.3.attn.hook_v\n",
      "blocks.3.attn.hook_z\n",
      "blocks.3.attn.hook_attn_scores\n",
      "blocks.3.attn.hook_pattern\n",
      "blocks.3.attn.hook_result\n",
      "blocks.3.attn.hook_rot_k\n",
      "blocks.3.attn.hook_rot_q\n",
      "blocks.3.mlp\n",
      "blocks.3.mlp.hook_pre\n",
      "blocks.3.mlp.hook_post\n",
      "blocks.3.hook_attn_in\n",
      "blocks.3.hook_q_input\n",
      "blocks.3.hook_k_input\n",
      "blocks.3.hook_v_input\n",
      "blocks.3.hook_mlp_in\n",
      "blocks.3.hook_attn_out\n",
      "blocks.3.hook_mlp_out\n",
      "blocks.3.hook_resid_pre\n",
      "blocks.3.hook_resid_post\n",
      "blocks.4\n",
      "blocks.4.ln1\n",
      "blocks.4.ln1.hook_scale\n",
      "blocks.4.ln1.hook_normalized\n",
      "blocks.4.ln2\n",
      "blocks.4.ln2.hook_scale\n",
      "blocks.4.ln2.hook_normalized\n",
      "blocks.4.attn\n",
      "blocks.4.attn.hook_k\n",
      "blocks.4.attn.hook_q\n",
      "blocks.4.attn.hook_v\n",
      "blocks.4.attn.hook_z\n",
      "blocks.4.attn.hook_attn_scores\n",
      "blocks.4.attn.hook_pattern\n",
      "blocks.4.attn.hook_result\n",
      "blocks.4.attn.hook_rot_k\n",
      "blocks.4.attn.hook_rot_q\n",
      "blocks.4.mlp\n",
      "blocks.4.mlp.hook_pre\n",
      "blocks.4.mlp.hook_post\n",
      "blocks.4.hook_attn_in\n",
      "blocks.4.hook_q_input\n",
      "blocks.4.hook_k_input\n",
      "blocks.4.hook_v_input\n",
      "blocks.4.hook_mlp_in\n",
      "blocks.4.hook_attn_out\n",
      "blocks.4.hook_mlp_out\n",
      "blocks.4.hook_resid_pre\n",
      "blocks.4.hook_resid_post\n",
      "blocks.5\n",
      "blocks.5.ln1\n",
      "blocks.5.ln1.hook_scale\n",
      "blocks.5.ln1.hook_normalized\n",
      "blocks.5.ln2\n",
      "blocks.5.ln2.hook_scale\n",
      "blocks.5.ln2.hook_normalized\n",
      "blocks.5.attn\n",
      "blocks.5.attn.hook_k\n",
      "blocks.5.attn.hook_q\n",
      "blocks.5.attn.hook_v\n",
      "blocks.5.attn.hook_z\n",
      "blocks.5.attn.hook_attn_scores\n",
      "blocks.5.attn.hook_pattern\n",
      "blocks.5.attn.hook_result\n",
      "blocks.5.attn.hook_rot_k\n",
      "blocks.5.attn.hook_rot_q\n",
      "blocks.5.mlp\n",
      "blocks.5.mlp.hook_pre\n",
      "blocks.5.mlp.hook_post\n",
      "blocks.5.hook_attn_in\n",
      "blocks.5.hook_q_input\n",
      "blocks.5.hook_k_input\n",
      "blocks.5.hook_v_input\n",
      "blocks.5.hook_mlp_in\n",
      "blocks.5.hook_attn_out\n",
      "blocks.5.hook_mlp_out\n",
      "blocks.5.hook_resid_pre\n",
      "blocks.5.hook_resid_post\n",
      "ln_final\n",
      "ln_final.hook_scale\n",
      "ln_final.hook_normalized\n",
      "unembed\n"
     ]
    }
   ],
   "source": [
    "for name, _ in cp_task.model.named_modules():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cupbearer import scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|██████████| 256/256 [00:08<00:00, 29.23it/s]\n",
      "\u001b[32m2024-06-24 16:39:02.963\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcupbearer.detectors.anomaly_detector\u001b[0m:\u001b[36meval\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1mAUC_ROC (all): 0.8155\u001b[0m\n",
      "\u001b[32m2024-06-24 16:39:02.963\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcupbearer.detectors.anomaly_detector\u001b[0m:\u001b[36meval\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mAP (all): 0.7761\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(defaultdict(dict,\n",
       "             {'all': {'AUC_ROC': 0.8155250549316406,\n",
       "               'AP': 0.7760751992220405}}),\n",
       " {'all': <Figure size 640x480 with 1 Axes>})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkEAAAHHCAYAAAC4BYz1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAABaf0lEQVR4nO3dd1QU19sH8O/SQZqCgNiwIIJgRRR7IbHXGHsEW4oQC2qiP2M0sddolNiCoNGoMZYYW1RsiaKCig2VqFiiAhaKgNL2vn94mNeVIiwLC873c86ew965c+eZu+A+3rl3RiGEECAiIiKSGR1tB0BERESkDUyCiIiISJaYBBEREZEsMQkiIiIiWWISRERERLLEJIiIiIhkiUkQERERyRKTICIiIpIlJkFEREQkS0yCiN4DCoUCM2fO1HYYZUJwcDAUCgXu3r0rlbVr1w7t2rUrkeO//VnNnDkTCoUCT58+LZHjOzg4wMfHp0SOlZuFCxeibt26UCqVhd737diPHz8OhUKB48ePS2UDBw5E//79NRApyQGTIJKFn376CQqFAs2aNdN2KPSeOH36NGbOnImEhARth5JDaY0tKSkJCxYswNdffw0dneL5+vn666+xY8cOXLp0qVjap/cLkyCShc2bN8PBwQHnzp3DrVu3tB0OlTKHDh3CoUOHCrXP6dOn8d133xU60Xj58iW++eabQu1TWPnFdvPmTaxbt65Yj5+X9evXIzMzE4MGDSq2YzRq1Aju7u5YsmRJsR2D3h9Mgui9Fx0djdOnT2Pp0qWoWLEiNm/erO2Q6B1SUlJK9HgGBgYwMDAotvaVSiVevXoFADAyMoKenl6xHetdDA0Noa+vr5VjBwUFoWfPnjAyMirW4/Tv3x87d+5EcnJysR6Hyj4mQfTe27x5M8qXL49u3bqhX79+uSZBd+/ehUKhwOLFi7F27VrUqlULhoaGaNq0KcLCwnLUP3r0KFq3bo1y5crB0tISvXr1wvXr11XqZM/1iIqKwtChQ2FhYYGKFSti+vTpEELgwYMH6NWrF8zNzWFnZ5fjf67p6en49ttv0aRJE1hYWKBcuXJo3bo1jh07lu/5Hjt2DAqFArt27cqx7ddff4VCoUBoaGie+2dkZOC7776Do6MjjIyMYGVlhVatWuHw4cMq9W7cuIH+/fujYsWKMDY2hpOTE6ZNm6ZS5+LFi+jSpQvMzc1hamqKjh074syZMyp1sufonDhxAmPGjIGNjQ2qVKkibT9w4IDU12ZmZujWrRuuXbuWbx9ku3btGjp06ABjY2NUqVIFs2fPznUuSm5zglasWIF69erBxMQE5cuXh7u7O3799VcArz/byZMnAwBq1KgBhUKhMs9IoVDAz88PmzdvRr169WBoaIiDBw9K23Kbv/X06VP0798f5ubmsLKywrhx46TECfj/39Hg4OAc+77Z5rtiy21O0J07d/Dxxx+jQoUKMDExQfPmzbFv3z6VOtnzb3777TfMmTMHVapUgZGRETp27Fig0dXo6GhcvnwZXl5eObYtXrwYLVq0gJWVFYyNjdGkSRP8/vvv72wzLx988AFSUlJy/M4SvU17/x0hKiGbN29G3759YWBggEGDBmHVqlUICwtD06ZNc9T99ddf8eLFC3z22WdQKBRYuHAh+vbtizt37kj/ez5y5Ai6dOmCmjVrYubMmXj58iVWrFiBli1b4sKFC3BwcFBpc8CAAXB2dsb8+fOxb98+zJ49GxUqVMCaNWvQoUMHLFiwAJs3b8akSZPQtGlTtGnTBsDr+RM///wzBg0ahNGjR+PFixcIDAxEp06dcO7cOTRs2DDX823Xrh2qVq2KzZs3o0+fPjn6olatWvD09Myzv2bOnIl58+Zh1KhR8PDwQFJSEsLDw3HhwgV88MEHAIDLly+jdevW0NfXx6effgoHBwfcvn0bf/75J+bMmQPgdQLSunVrmJub46uvvoK+vj7WrFmDdu3a4cSJEznmZ40ZMwYVK1bEt99+K40E/fLLL/D29kanTp2wYMECpKamYtWqVWjVqhUuXryYo6/fFBMTg/bt2yMzMxNTpkxBuXLlsHbtWhgbG+e5T7Z169Zh7Nix6Nevn5SMXL58GWfPnsXgwYPRt29fREVFYcuWLfjhhx9gbW0NAKhYsaLUxtGjR/Hbb7/Bz88P1tbW+cYKvB69cHBwwLx583DmzBn8+OOPiI+Px8aNG98Z75sKEtubYmNj0aJFC6SmpmLs2LGwsrLChg0b0LNnT/z+++85fofmz58PHR0dTJo0CYmJiVi4cCGGDBmCs2fP5hvX6dOnAQCNGzfOsW358uXo2bMnhgwZgvT0dGzduhUff/wx9u7di27duhXq/AHAxcUFxsbGOHXqVI74iVQIovdYeHi4ACAOHz4shBBCqVSKKlWqiHHjxqnUi46OFgCElZWVeP78uVT+xx9/CADizz//lMoaNmwobGxsxLNnz6SyS5cuCR0dHTFs2DCpbMaMGQKA+PTTT6WyzMxMUaVKFaFQKMT8+fOl8vj4eGFsbCy8vb1V6qalpanEGR8fL2xtbcWIESNUygGIGTNmSO+nTp0qDA0NRUJCglQWFxcn9PT0VOrlpkGDBqJbt2751mnTpo0wMzMT9+7dUylXKpXSz7179xYGBgbi9u3bUtmjR4+EmZmZaNOmjVQWFBQkAIhWrVqJzMxMqfzFixfC0tJSjB49WuUYMTExwsLCIkf528aPHy8AiLNnz0plcXFxwsLCQgAQ0dHRUnnbtm1F27Ztpfe9evUS9erVy7f9RYsW5WgnGwCho6Mjrl27luu2Nz+D7N+Tnj17qtQbM2aMACAuXbokhPj/39GgoKB3tplfbNWrV1f5Pcvup7///lsqe/HihahRo4ZwcHAQWVlZQgghjh07JgAIZ2dnld/L5cuXCwDiypUrOY71pm+++UYAEC9evMixLTU1VeV9enq6cHV1FR06dMg39uyYjh07lqPNOnXqiC5duuQbExEvh9F7bfPmzbC1tUX79u0BvL5sMGDAAGzduhVZWVk56g8YMADly5eX3rdu3RrA68sFAPD48WNERETAx8cHFSpUkOrVr18fH3zwAfbv35+jzVGjRkk/6+rqwt3dHUIIjBw5Uiq3tLSEk5OTdJzsutnzVJRKJZ4/f47MzEy4u7vjwoUL+Z73sGHDkJaWpnJJYdu2bcjMzMTQoUPz3dfS0hLXrl3Dv//+m+v2J0+e4OTJkxgxYgSqVaumsk2hUAAAsrKycOjQIfTu3Rs1a9aUtleqVAmDBw/GP//8g6SkJJV9R48eDV1dXen94cOHkZCQgEGDBuHp06fSS1dXF82aNXvnZcH9+/ejefPm8PDwkMoqVqyIIUOG5Ltfdh/8999/uV4KLai2bdvCxcWlwPV9fX1V3n/55ZcAkOvvlCbt378fHh4eaNWqlVRmamqKTz/9FHfv3kVkZKRK/eHDh6vMn3r7byQvz549g56eHkxNTXNse3N0Lj4+HomJiWjduvU7f8/zU758+RK77QCVXUyC6L2VlZWFrVu3on379oiOjsatW7dw69YtNGvWDLGxsQgJCcmxz9tf6tkJUXx8PADg3r17AAAnJ6cc+zo7O+Pp06c5JvW+3aaFhQWMjIykyxRvlmcfJ9uGDRtQv359aW5OxYoVsW/fPiQmJuZ77nXr1kXTpk1V5j9t3rwZzZs3R+3atfPd9/vvv0dCQgLq1KkDNzc3TJ48GZcvX5a2Z3/Zubq65tnGkydPkJqammc/KZVKPHjwQKW8Ro0aKu+zk7AOHTqgYsWKKq9Dhw4hLi4u3/O4d+8eHB0dc5TnFtPbvv76a5iamsLDwwOOjo7w9fXFqVOn3rnfm94+n3d5O9ZatWpBR0dH5X5GxeHevXt5fk7Z29/0rr8RdezduxfNmzeHkZERKlSogIoVK2LVqlXv/D3PjxBCSsqJ8sIkiN5bR48exePHj7F161Y4OjpKr+wbqeU2QfrNkYg3CSHUjiO3NgtynE2bNsHHxwe1atVCYGAgDh48iMOHD6NDhw4FutHcsGHDcOLECfz333+4ffs2zpw5885RIABo06YNbt++jfXr18PV1RU///wzGjdujJ9//vmd+xbF23N1ss/xl19+weHDh3O8/vjjj2KLxdnZGTdv3sTWrVvRqlUr7NixA61atcKMGTMK3EZB5h7l5+0v8Ly+0HMb0SxO6v6NWFlZITMzEy9evFAp//vvv6UVYz/99BP279+Pw4cPY/DgwUX6u4uPj8/xHw2it3FiNL23Nm/eDBsbGwQEBOTYtnPnTuzatQurV68u1JdV9erVAby+18rbbty4AWtra5QrV079oN/w+++/o2bNmti5c6fKF2BBv4gHDhwIf39/bNmyBS9fvoS+vj4GDBhQoH0rVKiA4cOHY/jw4UhOTkabNm0wc+ZMjBo1Srq8dfXq1Tz3r1ixIkxMTPLsJx0dHVStWjXfGGrVqgUAsLGxyXVF0btUr14910t6ucWUm3LlymHAgAEYMGAA0tPT0bdvX8yZMwdTp06FkZGRxkcZ/v33X5XRo1u3bkGpVEoTqrNHXN6+98/bIzVA3glTbqpXr57n55S9XRPq1q0L4PUqsfr160vlO3bsgJGREf766y8YGhpK5UFBQWofKzMzEw8ePEDPnj3VD5hkgSNB9F56+fIldu7cie7du6Nfv345Xn5+fnjx4gX27NlTqHYrVaqEhg0bYsOGDSpfRlevXsWhQ4fQtWtXjZ1D9v+43/zf8NmzZ/Nd3v4ma2trdOnSBZs2bcLmzZvRuXPnAv3P+NmzZyrvTU1NUbt2baSlpQF4neC0adMG69evx/3791XqZseqq6uLDz/8EH/88YfK5ZzY2Fj8+uuvaNWqFczNzfONo1OnTjA3N8fcuXORkZGRY/uTJ0/y3b9r1644c+YMzp07p7JPQe4T9XYfGBgYwMXFBUIIKZbsZFdTd2V+O1lfsWIFAKBLly4AAHNzc1hbW+PkyZMq9X766accbRUmtq5du+LcuXMqv1cpKSlYu3YtHBwcCjWvKT/ZKxLDw8NVynV1daFQKFRGtO7evYvdu3erfazIyEi8evUKLVq0ULsNkgeOBNF7ac+ePXjx4kWe/xNs3ry5dOPEgo6OZFu0aBG6dOkCT09PjBw5Uloib2FhodHnd3Xv3h07d+5Enz590K1bN0RHR2P16tVwcXEp8E3ghg0bhn79+gEAZs2aVaB9XFxc0K5dOzRp0gQVKlRAeHg4fv/9d/j5+Ul1fvzxR7Rq1QqNGzfGp59+iho1auDu3bvYt28fIiIiAACzZ8/G4cOH0apVK4wZMwZ6enpYs2YN0tLSsHDhwnfGYW5ujlWrVuGTTz5B48aNMXDgQFSsWBH379/Hvn370LJlS6xcuTLP/b/66iv88ssv6Ny5M8aNGyctka9evbrKHKfcfPjhh7Czs0PLli1ha2uL69evY+XKlejWrRvMzMwAAE2aNAEATJs2DQMHDoS+vj569Oih9khgdHQ0evbsic6dOyM0NBSbNm3C4MGD0aBBA6nOqFGjMH/+fIwaNQru7u44efIkoqKicrRVmNimTJmCLVu2oEuXLhg7diwqVKiADRs2IDo6Gjt27NDY4y1q1qwJV1dXHDlyBCNGjJDKu3XrhqVLl6Jz584YPHgw4uLiEBAQgNq1a7/zc8rL4cOHYWJiIt3SgShPWluXRlSMevToIYyMjERKSkqedXx8fIS+vr54+vSptPx40aJFOerhreXHQghx5MgR0bJlS2FsbCzMzc1Fjx49RGRkpEqd7KXPT548USn39vYW5cqVy3Gctm3bqizLViqVYu7cuaJ69erC0NBQNGrUSOzdu1d4e3uL6tWrvzNGIYRIS0sT5cuXFxYWFuLly5d59sWbZs+eLTw8PISlpaUwNjYWdevWFXPmzBHp6ekq9a5evSr69OkjLC0thZGRkXBychLTp09XqXPhwgXRqVMnYWpqKkxMTET79u3F6dOnVepkL5EPCwvLNZ5jx46JTp06CQsLC2FkZCRq1aolfHx8RHh4+DvP5fLly6Jt27bCyMhIVK5cWcyaNUsEBga+c4n8mjVrRJs2bYSVlZUwNDQUtWrVEpMnTxaJiYkq7c+aNUtUrlxZ6OjoqLQJQPj6+uYa09ufVfbvSWRkpOjXr58wMzMT5cuXF35+fjk+s9TUVDFy5EhhYWEhzMzMRP/+/UVcXFyun39esb29zFwIIW7fvi369esnfZYeHh5i7969KnWyl6Nv375dpTy/pftvW7p0qTA1Nc2xJD4wMFA4OjoKQ0NDUbduXREUFCT1y5sKukS+WbNmYujQoe+Mh0ghRBFmnhFRqZaZmQl7e3v06NEDgYGB2g6HZC4xMRE1a9bEwoULVW4RoUkRERFo3LgxLly4kOcNRYmycU4Q0Xts9+7dePLkCYYNG6btUIhgYWGBr776CosWLSrQCkd1zJ8/H/369WMCRAXCkSCi99DZs2dx+fJlzJo1C9bW1kW66RwR0fuKI0FE76FVq1bhiy++gI2NTaGfPUVEJBdlfiQoISEBXl5eyMzMRGZmJsaNG4fRo0drOywiIiIq5cp8EpSVlYW0tDSYmJggJSUFrq6uCA8Ph5WVlbZDIyIiolKszF8O09XVhYmJCQAgLS0NQogi3WqdiIiI5EHrN0s8efIkFi1ahPPnz+Px48fYtWsXevfurVInICAAixYtQkxMDBo0aIAVK1aoPBk6ISEBbdu2xb///otFixYV6nkxSqUSjx49gpmZGR+2R0REVEYIIfDixQvY29urf1NPLd2fSLJ//34xbdo0sXPnTgFA7Nq1S2X71q1bhYGBgVi/fr24du2aGD16tLC0tBSxsbE52oqJiREtWrQQMTExBT7+gwcPBAC++OKLL7744qsMvh48eKB2DlKq5gQpFIocI0HNmjVD06ZNpdvjK5VKVK1aFV9++SWmTJmSo40xY8agQ4cO0qMC3paWliY9Awl4ffOuatWq4cGDB+98lhERERGVDklJSahatSoSEhJgYWGhVhtavxyWn/T0dJw/fx5Tp06VynR0dODl5SU97C82NhYmJiYwMzNDYmIiTp48iS+++CLPNufNm4fvvvsuR7m5uTmTICIiojKmKFNZSvXE6KdPnyIrKwu2trYq5ba2toiJiQEA3Lt3D61bt0aDBg3QunVrfPnll3Bzc8uzzalTpyIxMVF6PXjwoFjPgYiIiEqnUj0SVBAeHh7SU6sLwtDQEIaGhsUXEBEREZUJpXokyNraGrq6uoiNjVUpj42NhZ2dnZaiIiIiovdBqR4JMjAwQJMmTRASEiJNllYqlQgJCYGfn592gyMiohKlVCqRnp6u7TCohOjr60NXV7dYj6H1JCg5ORm3bt2S3kdHRyMiIgIVKlRAtWrV4O/vD29vb7i7u8PDwwPLli1DSkoKhg8fXqTjBgQEICAgAFlZWUU9BSIiKmbp6emIjo4utqfPU+lkaWkJOzu7YruPn9aXyB8/fhzt27fPUe7t7Y3g4GAAwMqVK6WbJTZs2BA//vgjmjVrppHjJyUlwcLCAomJiVwdRkRUCgkhcP/+fWRkZBTtxnhUZgghkJqairi4OFhaWqJSpUo56mji+1vrSZC2MQkiIirdMjIycOvWLdjb26t9Pxgqm549e4a4uDjUqVMnx6UxTXx/M50mIqJSLXvagoGBgZYjoZKW/WzQjIyMYmmfSRAREZUJfL6j/BT3Z84kiIiIiGRJtklQQEAAXFxc0LRpU22HQkREVCocP34cCoUCCQkJ2g6lRGh9iby2+Pr6wtfXV5pYRUREZcsPh6NK9HgTPqhTqPo+Pj7YsGED5s2bp/LA7927d6NPnz6Q+bqkUkG2I0FERETFzcjICAsWLEB8fLzG2uQNIzWHSRAREVEx8fLygp2dHebNm5dnnR07dqBevXowNDSEg4MDlixZorLdwcEBs2bNwrBhw2Bubo5PP/0UwcHBsLS0xN69e+Hk5AQTExP069cPqamp2LBhAxwcHFC+fHmMHTtW5abAv/zyC9zd3WFmZgY7OzsMHjwYcXFxxXb+pZ1sL4eVhNyGags7nEpERGWXrq4u5s6di8GDB2Ps2LGoUqWKyvbz58+jf//+mDlzJgYMGIDTp09jzJgxsLKygo+Pj1Rv8eLF+PbbbzFjxgwAwN9//43U1FT8+OOP2Lp1K168eIG+ffuiT58+sLS0xP79+3Hnzh189NFHaNmyJQYMGADg9VLzWbNmwcnJCXFxcfD394ePjw/2799fYn1SmjAJIiIiKkZ9+vRBw4YNMWPGDAQGBqpsW7p0KTp27Ijp06cDAOrUqYPIyEgsWrRIJQnq0KEDJk6cKL3/+++/kZGRgVWrVqFWrVoAgH79+uGXX35BbGwsTE1N4eLigvbt2+PYsWNSEjRixAipjZo1a+LHH39E06ZNkZycDFNT0+LqglKLl8OIiIiK2YIFC7BhwwZcv35dpfz69eto2bKlSlnLli3x77//qlzGcnd3z9GmiYmJlAABgK2tLRwcHFSSGVtbW5XLXefPn0ePHj1QrVo1mJmZoW3btgCA+/fvF+0EyyjZJkFcIk9ERCWlTZs26NSpE6ZOnarW/uXKlctRpq+vr/JeoVDkWpb90NmUlBR06tQJ5ubm2Lx5M8LCwrBr1y4A8p1sLdvLYVwiT0REJWn+/Plo2LAhnJycpDJnZ2ecOnVKpd6pU6dyfVZWUd24cQPPnj3D/PnzUbVqVQBAeHi4Ro9R1sh2JIiIiKgkubm5YciQIfjxxx+lsokTJyIkJASzZs1CVFQUNmzYgJUrV2LSpEkaP361atVgYGCAFStW4M6dO9izZw9mzZql8eOUJUyCiIiISsj3338vXZ4CgMaNG+O3337D1q1b4erqim+//Rbff/+9yqRoTalYsSKCg4Oxfft2uLi4YP78+Vi8eLHGj1OWKITMb1mZfTksMTER5ubmGm2bS+SJiIru1atXiI6ORo0aNWBkZKTtcKgE5ffZa+L7myNBREREJEtMgoiIiEiWmAQRERGRLMk2CeJ9goiIiORNtkmQr68vIiMjERYWpu1QiIiISAtkmwQRERGRvDEJIiIiIlliEkRERESyxCSIiIiIZIlJEBEREeXg4OCAZcuWaTuMYiXbp8gTEVEZd2xeyR6v/VS1dgsNDUWrVq3QuXNn7Nu3T8NBUVFwJIiIiKgYBQYG4ssvv8TJkyfx6NEjbYdDb5BtEsSbJRIRUXFLTk7Gtm3b8MUXX6Bbt24IDg6Wth0/fhwKhQIhISFwd3eHiYkJWrRogZs3b6q0sWrVKtSqVQsGBgZwcnLCL7/8orJdoVBgzZo16N69O0xMTODs7IzQ0FDcunUL7dq1Q7ly5dCiRQvcvn1b2uf27dvo1asXbG1tYWpqiqZNm+LIkSP5nsv9+/fRq1cvmJqawtzcHP3790dsbKy03cfHB71791bZZ/z48WjXrp30/vfff4ebmxuMjY1hZWUFLy8vpKSkFLA3NU+2SRBvlkhERMXtt99+Q926deHk5IShQ4di/fr1EEKo1Jk2bRqWLFmC8PBw6OnpYcSIEdK2Xbt2Ydy4cZg4cSKuXr2Kzz77DMOHD8exY8dU2pg1axaGDRuGiIgI1K1bF4MHD8Znn32GqVOnIjw8HEII+Pn5SfWTk5PRtWtXhISE4OLFi+jcuTN69OiB+/fv53oeSqUSvXr1wvPnz3HixAkcPnwYd+7cwYABAwrcF48fP8agQYMwYsQIXL9+HcePH0ffvn1z9EdJ4pwgIiKiYhIYGIihQ4cCADp37ozExEScOHFCZXRkzpw5aNu2LQBgypQp6NatG169egUjIyMsXrwYPj4+GDNmDADA398fZ86cweLFi9G+fXupjeHDh6N///4AgK+//hqenp6YPn06OnXqBAAYN24chg8fLtVv0KABGjRoIL2fNWsWdu3ahT179qgkS9lCQkJw5coVREdHo2rVqgCAjRs3ol69eggLCyvQVZXHjx8jMzMTffv2RfXq1QEAbm5u7+7EYiTbkSAiIqLidPPmTZw7dw6DBg0CAOjp6WHAgAEIDAxUqVe/fn3p50qVKgEA4uLiAADXr19Hy5YtVeq3bNkS169fz7MNW1tbAKoJhq2tLV69eoWkpCQAr0eCJk2aBGdnZ1haWsLU1BTXr1/PcyTo+vXrqFq1qpQAAYCLiwssLS1zxJKXBg0aoGPHjnBzc8PHH3+MdevWIT4+vkD7FhcmQURERMUgMDAQmZmZsLe3h56eHvT09LBq1Srs2LEDiYmJUj19fX3pZ4VCAeD15afCyK2N/NqdNGkSdu3ahblz5+Lvv/9GREQE3NzckJ6eXsiz/H86Ojo5Lm1lZGRIP+vq6uLw4cM4cOAAXFxcsGLFCjg5OSE6OlrtYxYVkyAiIiINy8zMxMaNG7FkyRJERERIr0uXLsHe3h5btmwpUDvOzs44deqUStmpU6fg4uJSpPhOnToFHx8f9OnTB25ubrCzs8Pdu3fzjePBgwd48OCBVBYZGYmEhAQplooVK+Lx48cq+0VERKi8VygUaNmyJb777jtcvHgRBgYG2LVrV5HOpSg4J4iIiEjD9u7di/j4eIwcORIWFhYq2z766CMEBgZi0aJF72xn8uTJ6N+/Pxo1agQvLy/8+eef2Llz5ztXcr2Lo6Mjdu7ciR49ekChUGD69On5jj55eXnBzc0NQ4YMwbJly5CZmYkxY8agbdu2cHd3BwB06NABixYtwsaNG+Hp6YlNmzbh6tWraNSoEQDg7NmzCAkJwYcffggbGxucPXsWT548gbOzc5HOpSg4EkRERKRhgYGB8PLyypEAAa+ToPDwcFy+fPmd7fTu3RvLly/H4sWLUa9ePaxZswZBQUEqE6vVsXTpUpQvXx4tWrRAjx490KlTJzRu3DjP+gqFAn/88QfKly+PNm3awMvLCzVr1sS2bdukOp06dcL06dPx1VdfoWnTpnjx4gWGDRsmbTc3N8fJkyfRtWtX1KlTB9988w2WLFmCLl26FOlcikIhtLk2rRRISkqChYUFEhMTYW5urtG2fzgclaNswgd1NHoMIqL33atXrxAdHY0aNWrAyMhI2+FQCcrvs9fE9zdHgoiIiEiWmAQRERGRLMk2CeJjM4iIiORNtkkQH5tBREQkb7JNgoiIqGyR+ToeWSruz5xJEBERlWq6uroAUKS7GVPZlJqaCkD17teaxJslEhFRqaanpwcTExM8efIE+vr60NHh/9/fd0IIpKamIi4uDpaWllIirGlMgoiIqFRTKBSoVKkSoqOjce/ePW2HQyXI0tISdnZ2xdY+kyAiIir1DAwM4OjoyEtiMqKvr19sI0DZmAQREVGZoKOjwztGk0bxwioRERHJEpMgIiIikiUmQURERCRLTIKIiIhIlpgEERERkSwxCSIiIiJZYhJEREREsiTbJCggIAAuLi5o2rSptkMhIiIiLZBtEuTr64vIyEiEhYVpOxQiIiLSAtkmQURERCRvTIKIiIhIlpgEERERkSwxCSIiIiJZ4lPkiYhIFhISErBt2zbs2bMHjx49QlZWlrZDojxYWFigQ4cOGDJkCOrUqVNsx2ESRERE7724uDh07NgRkZGRaNeuHTw9PaGnx6/A0kipVCIuLg7Lli3DokWLsG/fPrRv375YjsXfACIieu+NHTsWcXFxuHLlClxcXLQdDhVAamoqevXqhb59+yImJgaGhoYaPwbnBBER0XstNTUVf/75J8aPH88EqAwxMTHBDz/8gISEBBw+fLhYjsEkiIiI3mu3b99Gamoq2rZtq+1QqJDq1asHKysrXLp0qVjaZxJERETvtVevXgEAypUrp+VIqLAUCgXKlSuHly9fFkv7TIKIiEgWFApFnttCQ0Ohq6uLbt265dh2/PhxKBQKJCQk5Njm4OCAZcuWqRwj+2Vubo6mTZvijz/+yLHfy5cvMWPGDNSpUweGhoawtrbGxx9/jGvXruWom5SUhGnTpqFu3bowMjKCnZ0dvLy8sHPnTgghCnbyAJKTk+Hn54cqVarA2NgYLi4uWL16tUqdtWvXol27djA3N8/znHPz8OFDDB06FFZWVjA2NoabmxvCw8Ol7YsXL4aNjQ1sbGywZMkSlX3Pnj2LJk2aIDMzM9e28/vciopJEBERyV5gYCC+/PJLnDx5Eo8ePSpSW0FBQXj8+DHCw8PRsmVL9OvXD1euXJG2p6WlwcvLC+vXr8fs2bMRFRWF/fv3IzMzE82aNcOZM2ekugkJCWjRogU2btyIqVOn4sKFCzh58iQGDBiAr776ComJiQWOy9/fHwcPHsSmTZtw/fp1jB8/Hn5+ftizZ49UJzU1FZ07d8b//ve/ArcbHx+Pli1bQl9fHwcOHEBkZCSWLFmC8uXLAwAuX76Mb7/9Flu3bsWWLVvwzTffSP2RmZmJzz//HKtXr9bKaj2uDiMiIllLTk7Gtm3bEB4ejpiYGAQHBxcqCXibpaUl7OzsYGdnh1mzZmH58uU4duwY3NzcAADLli1DaGgoLl68iAYNGgAAqlevjh07dqBZs2YYOXIkrl69CoVCgf/973+4e/cuoqKiYG9vLx2jTp06GDRoEIyMjAoc1+nTp+Ht7Y127doBAD799FOsWbMG586dQ8+ePQEA48ePB/B69KugFixYgKpVqyIoKEgqq1GjhvTzjRs3UL9+fXTo0AEAUL9+fdy4cQNubm5YtGgR2rRpg6ZNmxb4eJrEkSAiIpK13377DXXr1oWTkxOGDh2K9evXF+oyU14yMzMRGBgIADAwMJDKf/31V3zwwQdSApRNR0cHEyZMQGRkJC5dugSlUomtW7diyJAhKglQNlNTU2n0ZObMmXBwcMg3nhYtWmDPnj14+PAhhBA4duwYoqKi8OGHHxbpPPfs2QN3d3d8/PHHsLGxQaNGjbBu3Tppu5ubG6KionD//n3cu3cPUVFRcHV1xe3btxEUFITZs2cX6fhFwSSIiIhkLTAwEEOHDgUAdO7cGYmJiThx4oTa7Q0aNAimpqYwNDTEhAkT4ODggP79+0vbo6Ki4OzsnOu+2eVRUVF4+vQp4uPjUbdu3Xce09raGrVq1cq3zooVK+Di4oIqVarAwMAAnTt3RkBAANq0aVOIs8vpzp07WLVqFRwdHfHXX3/hiy++wNixY7FhwwbpnObOnYsPPvgAH374IebNmwdnZ2d89tlnWLhwIf766y+4urqiUaNGOHnyZJFiKSxeDiMiItm6efMmzp07h127dgEA9PT0MGDAAAQGBkqXjQrrhx9+gJeXF+7cuYMJEybgxx9/RIUKFVTqFGSkqTCjUX5+fvDz88u3zooVK3DmzBns2bMH1atXx8mTJ+Hr6wt7e3t4eXkV+FhvUyqVcHd3x9y5cwEAjRo1wtWrV7F69Wp4e3sDAD7//HN8/vnn0j4bNmyAmZkZPD094eTkhLCwMPz3338YOHAgoqOji+XGiLlhElSMmt9fm0vp4hKPg4iIchcYGIjMzEyVy01CCBgaGmLlypWwsLCAubk5ACAxMRGWlpYq+yckJMDCwkKlzM7ODrVr10bt2rURFBSErl27IjIyEjY2NgBez+e5fv16rvFkl9epUwcVK1aEpaUlbty4UeTzfPnyJf73v/9h165d0gq4+vXrIyIiAosXLy5SElSpUqUcN6F0dnbGjh07cq3/9OlTfPfddzh58iTOnj2LOnXqwNHREY6OjsjIyEBUVJQ0f6q48XIYERHJUmZmJjZu3IglS5YgIiJCel26dAn29vbYsmULAMDR0RE6Ojo4f/68yv537txBYmJivg/49PDwQJMmTTBnzhypbODAgThy5EiOGwAqlUr88MMPcHFxQYMGDaCjo4OBAwdi8+bNua5YS05OznNZ+dsyMjKQkZEBHR3Vr31dXV0olcoCtZGXli1b4ubNmyplUVFRqF69eq71J0yYgAkTJqBKlSrIyspCRkaGtC0zM7NEH2wr2yQoICAALi4uWpuRTkRE2rV3717Ex8dj5MiRcHV1VXl99NFH0qRmMzMzjBo1ChMnTsSePXsQHR2NkydPYsiQIWjevDlatGiR73HGjx+PNWvW4OHDhwBeJwEeHh7o0aMHtm/fjvv37yMsLAwfffQRrl+/jsDAQOneOHPmzEHVqlXRrFkzbNy4EZGRkfj333+xfv16NGrUCMnJyQCAlStXomPHjnnGYG5ujrZt22Ly5Mk4fvw4oqOjERwcjI0bN6JPnz5SvZiYGERERODWrVsAgCtXriAiIgLPnz+X6nTs2BErV66U3k+YMAFnzpzB3LlzcevWLfz6669Yu3YtfH19c8Rx+PBhREVFSduaNm2KGzdu4MCBA1i7di10dXXh5OSUb39qlJC5xMREAUAkJiZqvO3TP0/M8SIiopJ17tw5AUBcunRJpbx79+6ia9euue5z9uxZlX1evnwpZsyYIerWrSuMjY1FjRo1xKeffiqePHmish8AsWvXLpUypVIp6tatK7744gupLCUlRUybNk3Url1b6OvriwoVKoiPPvpIXLlyJUcsCQkJYsqUKcLR0VEYGBgIW1tb4eXlJXbt2iWUSqUQQogZM2aI6tWr59sPjx8/Fj4+PsLe3l4YGRkJJycnsWTJEqmN7HYA5HgFBQVJdapXry5mzJih0vaff/4pXF1dhaGhoahbt65Yu3ZtjuOnpqaKOnXqiIsXL6qUr1u3Ttja2opq1aqJvXv35tivevXqYtq0aTnKNfH9rRBCA+sAy7CkpCRYWFggMTFRuu6rKaGBk3KUeY7knCAiopIUFhYGDw8PXLp0CfXr19d2OFRIDg4OGDp0aI6l9Jr4/pbt5TAiIiKSNyZBREREJEtMgoiIiEiWmAQRERGRLDEJIiIiIlliEkRERFQK1K1bF4aGhoiJicmxrV27dlAoFFAoFDAyMoKLiwt++umnQrXv4+MjtfHmq169elIdBweHXOvkds+fNyUkJMDX1xeVKlWCoaEh6tSpg/3790vbN2/ejKpVq6J8+fLw9/dX2ffu3buoU6cOkpKSCnU+msAkiIiISMv++ecfvHz5Ev369ZMePPq20aNH4/Hjx4iMjET//v3h6+sr3dW6IJYvX47Hjx9LrwcPHqBChQr4+OOPpTphYWEqdQ4fPgwAKnXelp6ejg8++AB3797F77//jps3b2LdunWoXLkygNePyRg1ahQWL16MQ4cOYdOmTdi7d6+0/5gxYzB//nyN36amIPjsMCIiIi0LDAzE4MGD0bZtW4wbNw5ff/11jjomJiaws7MDAMycORO//vor9uzZg0GDBhXoGBYWFirPOdu9ezfi4+MxfPhwqaxixYoq+8yfPx+1atVC27Zt82x3/fr1eP78OU6fPg19fX0Ar0eUst25cwcWFhYYMGAAAKB9+/a4fv06unfvji1btkBfXx99+/Yt0DloGkeCiIiItOjFixfYvn07hg4dig8++ACJiYn4+++/37mfsbEx0tPTAby+pKRQKHD8+PECHzcwMBBeXl55PuMrPT0dmzZtwogRI6THeORmz5498PT0hK+vL2xtbeHq6oq5c+dKzwBzdHREamoqLl68iOfPnyMsLAz169dHfHw8pk+frvIIjpLGJIiIiEiLtm7dCkdHR9SrVw+6uroYOHCg9Nyy3GRlZWHTpk24fPkyOnToAADQ19eHk5MTTExMCnTMR48e4cCBAxg1alSedXbv3o2EhAT4+Pjk29adO3fw+++/IysrC/v378f06dOxZMkS6Q7P5cuXx4YNGzBs2DB4eHhg2LBh6NSpEyZNmgQ/Pz9ER0ejUaNGcHV1xe+//16g+DWFl8OIiIi0aP369Rg6dKj0fujQoWjbti1WrFgBMzMzqfynn37Czz//jPT0dOjq6mLChAn44osvAACVK1fGjRs3CnzMDRs2wNLSEr17986zTmBgILp06QJ7e/t821IqlbCxsZEegNqkSRM8fPgQixYtwowZMwAAffr0UXlQ64kTJ3D58mWsWLECtWvXxpYtW2BnZwcPDw+0adMGNjY2BT6XouBIEBERkZZERkbizJkz+Oqrr6Cnpwc9PT00b94cqamp2Lp1q0rdIUOGICIiAtHR0UhJScHSpUuho1P4r3EhBNavX49PPvkEBgYGuda5d+8ejhw5ku9IUbZKlSqhTp060NXVlcqcnZ0RExMjXa57U1paGsaMGYM1a9bg1q1byMzMRNu2beHk5IQ6derg7NmzhT4ndTEJIiIi0pLAwEC0adMGly5dQkREhPTy9/fPcUnMwsICtWvXRuXKldVKfrKdOHECt27dwsiRI/OsExQUBBsbG3Tr1u2d7bVs2RK3bt2CUqmUyqKiolCpUqVck6zZs2ejc+fOaNy4MbKyspCZmSlty8jIkOYSlQQmQURERFqQkZGBX375BYMGDYKrq6vKa9SoUTh79iyuXbtWoLYePnyIunXr4ty5c++sGxgYiGbNmsHV1TXX7UqlEkFBQfD29oaeXs5ZM8OGDcPUqVOl91988QWeP3+OcePGISoqCvv27cPcuXNzvbdQZGQktm3bhu+//x7A63sj6ejoIDAwEPv27cONGzfQtGnTAp2zJnBOEBERkRbs2bMHz549U5krk83Z2RnOzs4IDAzE0qVL39lWRkYGbt68idTU1HzrJSYmYseOHVi+fHmedY4cOYL79+9jxIgRuW6/f/++ykhU1apV8ddff2HChAmoX78+KleunOsyfyEEPv30UyxduhTlypUD8HqFW3BwMHx9fZGWloaVK1dK9xcqCUyCiIiItOCjjz7K99JPZGSk9PO7lr47ODhACPHOY1pYWLwzUfrwww/zbSu3WDw9PXHmzJl821UoFPjnn39ylHfv3h3du3fPd9/iwsthREREJEtMgoiIiEiWmAQREdF7LXtyb27Ltan0S09Pz3WCtiYwCSIiovdalSpVoFAocOXKFW2HQoUUGxuL2NjYPB/tUVRMgoiI6L1WsWJFtGrVCj/99NM7JwVT6bJs2TIoFAr06NGjWNrn6jAiInrvzZ07F507d0azZs0wbNgwODk5SU88p9JFqVQiNjYWu3fvxp9//onvv/8e1tbWxXIsJkFERPTea9WqFY4cOYIFCxZg+vTpSEtL03ZI9A4eHh5Yt25dgR7doS4mQUREJAvNmzfHrl27kJ6ejvj4+BJ9PAMVjrm5OUxNTYv9OEyCiIhIVgwMDGBra6vtMKgU4MRoIiIikiUmQURERCRLZT4JevDgAdq1awcXFxfUr18f27dv13ZIREREVAaU+TlBenp6WLZsGRo2bIiYmBg0adIEXbt2lZ5QS0RERJSbMp8EVapUCZUqVQIA2NnZwdraGs+fP2cSRERERPnS+uWwkydPokePHrC3t4dCocDu3btz1AkICICDgwOMjIzQrFkznDt3Lte2zp8/j6ysLFStWrWYoyYiIqKyTutJUEpKCho0aICAgIBct2/btg3+/v6YMWMGLly4gAYNGqBTp06Ii4tTqff8+XMMGzYMa9euLYmwiYiIqIzT+uWwLl26oEuXLnluX7p0KUaPHo3hw4cDAFavXo19+/Zh/fr1mDJlCgAgLS0NvXv3xpQpU9CiRYt8j5eWlqZyp9CkpCQNnAURERGVNVofCcpPeno6zp8/Dy8vL6lMR0cHXl5eCA0NBQAIIeDj44MOHTrgk08+eWeb8+bNg4WFhfTipTMiIiJ5KtVJ0NOnT5GVlZXjzp62traIiYkBAJw6dQrbtm3D7t270bBhQzRs2BBXrlzJs82pU6ciMTFRej148KBYz4GIiIhKJ61fDiuqVq1aQalUFri+oaEhDA0NizEiIiIiKgtK9UiQtbU1dHV1ERsbq1IeGxsLOzs7LUVFRERE74NSnQQZGBigSZMmCAkJkcqUSiVCQkLg6empxciIiIiorNP65bDk5GTcunVLeh8dHY2IiAhUqFAB1apVg7+/P7y9veHu7g4PDw8sW7YMKSkp0moxdQUEBCAgIABZWVlFPQUiIiIqg7SeBIWHh6N9+/bSe39/fwCAt7c3goODMWDAADx58gTffvstYmJi0LBhQxw8eDDHZOnC8vX1ha+vL5KSkmBhYVGktoiIiKjs0XoS1K5dOwgh8q3j5+cHPz+/EoqIiIiI5KBUzwkiIiIiKi5MgoiIiEiWmAQRERGRLMk2CQoICICLiwuaNm2q7VCIiIhIC2SbBPn6+iIyMhJhYWHaDoWIiIi0QLZJEBEREckbkyAiIiKSJSZBREREJEtMgoiIiEiWmAQRERGRLMk2CeISeSIiInmTbRLEJfJERETyJtskiIiIiOSNSRARERHJEpMgIiIikiUmQURERCRLTIKIiIhIlpgEERERkSzJNgnifYKIiIjkTSGEENoOQpuSkpJgYWGBxMREmJuba7Tt0MBJOco8a1qpFrSfqtFjEhERyYEmvr9lOxJERERE8sYkiIiIiGSJSRARERHJEpMgIiIikiUmQURERCRLaiVBd+7c0XQcRERERCVKrSSodu3aaN++PTZt2oRXr15pOiYiIiKiYqdWEnThwgXUr18f/v7+sLOzw2effYZz585pOrZixZslEhERyZtaSVDDhg2xfPlyPHr0COvXr8fjx4/RqlUruLq6YunSpXjy5Imm49Q4X19fREZGIiwsTNuhEBERkRYUaWK0np4e+vbti+3bt2PBggW4desWJk2ahKpVq2LYsGF4/PixpuIkIiIi0qgiJUHh4eEYM2YMKlWqhKVLl2LSpEm4ffs2Dh8+jEePHqFXr16aipOIiIhIo/TU2Wnp0qUICgrCzZs30bVrV2zcuBFdu3aFjs7rnKpGjRoIDg6Gg4ODJmMlIiIi0hi1kqBVq1ZhxIgR8PHxQaVKlXKtY2Njg8DAwCIFR0RERFRc1EqC/v3333fWMTAwgLe3tzrNv9dC7zxTee/ZXkuBEBERyZxac4KCgoKwffv2HOXbt2/Hhg0bihwUERERUXFTKwmaN28erK2tc5Tb2Nhg7ty5RQ6KiIiIqLiplQTdv38fNWrUyFFevXp13L9/v8hBERERERU3tZIgGxsbXL58OUf5pUuXYGVlVeSgiIiIiIqbWknQoEGDMHbsWBw7dgxZWVnIysrC0aNHMW7cOAwcOFDTMRYLPjaDiIhI3tRaHTZr1izcvXsXHTt2hJ7e6yaUSiWGDRtWZuYE+fr6wtfXF0lJSbCwsNB2OERERFTC1EqCDAwMsG3bNsyaNQuXLl2CsbEx3NzcUL16dU3HR0RERFQs1EqCstWpUwd16tTRVCxEREREJUatJCgrKwvBwcEICQlBXFwclEqlyvajR49qJDhZODYvZ1n7qSUfBxERkcyolQSNGzcOwcHB6NatG1xdXaFQKDQdFxEREVGxUisJ2rp1K3777Td07dpV0/EQERERlQi1lsgbGBigdu3amo6FiIiIqMSolQRNnDgRy5cvhxBC0/EQERERlQi1Lof9888/OHbsGA4cOIB69epBX19fZfvOnTs1EhwRERFRcVErCbK0tESfPn00HQsRERFRiVErCQoKCtJ0HEREREQlSu2bJWZmZuL48eO4ffs2Bg8eDDMzMzx69Ajm5uYwNTXVZIzvtdA7z3KUebbXQiBEREQyo1YSdO/ePXTu3Bn3799HWloaPvjgA5iZmWHBggVIS0vD6tWrNR0nERERkUaptTps3LhxcHd3R3x8PIyNjaXyPn36ICQkRGPBERERERUXtUaC/v77b5w+fRoGBgYq5Q4ODnj48KFGAituAQEBCAgIQFZWlrZDISIiIi1QayRIqVTmmjz8999/MDMzK3JQJcHX1xeRkZEICwvTdihERESkBWqNBH344YdYtmwZ1q5dCwBQKBRITk7GjBkz+CgNTXj7oap8oCoREZHGqZUELVmyBJ06dYKLiwtevXqFwYMH499//4W1tTW2bNmi6RiJT5onIiLSOLWSoCpVquDSpUvYunUrLl++jOTkZIwcORJDhgxRmShNREREVFqpfZ8gPT09DB06VJOxEBEREZUYtZKgjRs35rt92LBhagVDREREVFLUSoLGjRun8j4jIwOpqakwMDCAiYkJkyAiIiIq9dRaIh8fH6/ySk5Oxs2bN9GqVStOjCYiIqIyQe05QW9zdHTE/PnzMXToUNy4cUNTzVJBcQUZERFRoag1EpQXPT09PHr0SJNNEhERERULtUaC9uzZo/JeCIHHjx9j5cqVaNmypUYCIyIiIipOaiVBvXv3VnmvUChQsWJFdOjQAUuWLNFEXERERETFSq0kSKlUajoOIiIiohKl0TlBRERERGWFWiNB/v7+Ba67dOlSdQ5BREREVKzUSoIuXryIixcvIiMjA05OTgCAqKgo6OrqonHjxlI9hUKhmSiJiIiINEytJKhHjx4wMzPDhg0bUL58eQCvb6A4fPhwtG7dGhMnTtRokERERESaplYStGTJEhw6dEhKgACgfPnymD17Nj788EMmQaUFb6BIRESUJ7UmRiclJeHJkyc5yp88eYIXL14UOSgiIiKi4qZWEtSnTx8MHz4cO3fuxH///Yf//vsPO3bswMiRI9G3b19Nx0hERESkcWpdDlu9ejUmTZqEwYMHIyMj43VDenoYOXIkFi1apNEAi0tAQAACAgKQlZWl7VDUk9ulLiIiIiowhRBCqLtzSkoKbt++DQCoVasWypUrp7HASkpSUhIsLCyQmJgIc3NzjbYdGjhJrf08a1ppNA4VnBNERETvAU18fxfpKfKPHz/G48eP0aZNGxgbG0MIwWXxGhB655nK+2JNiorT26NVTMCIiKgUUWtO0LNnz9CxY0fUqVMHXbt2xePHjwEAI0eO5MowIiIiKhPUSoImTJgAfX193L9/HyYmJlL5gAEDcPDgQY0FR0RERFRc1LocdujQIfz111+oUqWKSrmjoyPu3bunkcCohPBeQkREJFNqjQSlpKSojABle/78OQwNDYscFBEREVFxUysJat26NTZu3Ci9VygUUCqVWLhwIdq3b6+x4IiIiIiKi1qXwxYuXIiOHTsiPDwc6enp+Oqrr3Dt2jU8f/4cp06d0nSMpKa3V5kBgCdzVCIiIgBqjgS5uroiKioKrVq1Qq9evZCSkoK+ffvi4sWLqFWrlqZjJCIiItK4Qo8EZWRkoHPnzli9ejWmTZtWHDERERERFbtCJ0H6+vq4fPlyccRCpQVvckhERDKg1uWwoUOHIjAwUNOxEBEREZUYtSZGZ2ZmYv369Thy5AiaNGmS45lhS5cu1UhwRERERMWlUEnQnTt34ODggKtXr6Jx48YAgKioKJU6fHZYyXhvni9GRESkJYVKghwdHfH48WMcO3YMwOvHZPz444+wtbUtluCIiIiIikuh5gQJIVTeHzhwACkpKRoNiIiIiKgkqDUxOtvbSRERERFRWVGoy2EKhSLHnB/OASp+ud35WVZye8jr23Jbxl+Q/QrSDhUeH8xLRGVAoZIgIQR8fHykh6S+evUKn3/+eY7VYTt37tRchERERETFoFBJkLe3t8r7oUOHajQYIiIiopJSqCQoKCiouOKg0kxTlzZ4iYSIiEqRIk2MJiIiIiqrmAQRERGRLDEJIiIiIlliEkRERESypNYDVKkMU+feOQVphxOcSw4nmBMRaQRHgoiIiEiWmAQRERGRLL0XSVCfPn1Qvnx59OvXT9uhEBERURnxXswJGjduHEaMGIENGzZoOxQq6zjfhohINt6LkaB27drBzMxM22EQERFRGaL1JOjkyZPo0aMH7O3toVAosHv37hx1AgIC4ODgACMjIzRr1gznzp0r+UCJiIjovaL1JCglJQUNGjRAQEBArtu3bdsGf39/zJgxAxcuXECDBg3QqVMnxMXFlXCkRERE9D7R+pygLl26oEuXLnluX7p0KUaPHo3hw4cDAFavXo19+/Zh/fr1mDJlSqGPl5aWhrS0NOl9UlJS4YMmIiKiMk/rSVB+0tPTcf78eUyd+v8TU3V0dODl5YXQ0FC12pw3bx6+++47TYVIpYWmbgKpbtvqTp4uzrYLcixO+iYiGdP65bD8PH36FFlZWbC1tVUpt7W1RUxMjPTey8sLH3/8Mfbv348qVarkmyBNnToViYmJ0uvBgwfFFj8RERGVXqV6JKigjhw5UuC6hoaGMDQ0LMZoiIiIqCwo1SNB1tbW0NXVRWxsrEp5bGws7OzstBQVERERvQ9KdRJkYGCAJk2aICQkRCpTKpUICQmBp6enFiMjIiKisk7rl8OSk5Nx69Yt6X10dDQiIiJQoUIFVKtWDf7+/vD29oa7uzs8PDywbNkypKSkSKvF1BUQEICAgABkZWUV9RTee6F3nuUo86xppZnGOVmXiIi0ROtJUHh4ONq3by+99/f3BwB4e3sjODgYAwYMwJMnT/Dtt98iJiYGDRs2xMGDB3NMli4sX19f+Pr6IikpCRYWFkVqi4iIiMoerSdB7dq1gxAi3zp+fn7w8/MroYiIiIhIDkr1nCAiIiKi4sIkiIiIiGSJSRARERHJktbnBGkLV4flLbfVYO9UnI+tKAu0vcpN7v1PRKQG2Y4E+fr6IjIyEmFhYdoOhYiIiLRAtkkQERERyRuTICIiIpIlJkFEREQkS0yCiIiISJaYBBEREZEscYn8e7JEXq1l7aUVl3urKsn+KM6l/iXZtrYfwqvtWyZQ4fEzkyXZjgRxiTwREZG8yTYJIiIiInljEkRERESyxCSIiIiIZIlJEBEREckSkyAiIiKSJSZBREREJEu8T9B7cp+ggnr7fkKeNa000k5u1G37vVHa7l1D9CbeF4dIviNBvE8QERGRvMk2CSIiIiJ5YxJEREREssQkiIiIiGSJSRARERHJEpMgIiIikiUmQURERCRLTIKIiIhIlnizRJndLPFtBbnpYXEeqyA3VFR3P3WU5LFKhdxumPeuOrndUK8g7agbD2/g926aujFnaWuHqJjJdiSIN0skIiKSN9kmQURERCRvTIKIiIhIlpgEERERkSwxCSIiIiJZYhJEREREssQkiIiIiGSJSRARERHJEpMgIiIikiUmQURERCRLfGyGzB+bQcXn7UdweEJDj5aQu9L4iA5NPX6kOKnTbwXpI3U/Dz4ipfDYZxon25EgPjaDiIhI3mSbBBEREZG8MQkiIiIiWWISRERERLLEJIiIiIhkiUkQERERyRKTICIiIpIlJkFEREQkS0yCiIiISJaYBBEREZEsMQkiIiIiWWISRERERLLEJIiIiIhkiUkQERERyZKetgPQloCAAAQEBCArK0vboby3Qu880+qxPGtaqbVfafN2jAU5r2J1bF7ZPF5B2inJc8vtWO2nqrdfSSqLfVSQfUiWZDsS5Ovri8jISISFhWk7FCIiItIC2SZBREREJG9MgoiIiEiWmAQRERGRLDEJIiIiIlliEkRERESyxCSIiIiIZIlJEBEREckSkyAiIiKSJSZBREREJEtMgoiIiEiWmAQRERGRLDEJIiIiIlliEkRERESyxCSIiIiIZIlJEBEREckSkyAiIiKSJSZBREREJEtMgoiIiEiWmAQRERGRLOlpOwBtCQgIQEBAALKysrQdiqyF3nlWovtp6lieNa1K7PjqKkgfaf08js0r9C4F+jzUaJfKiLc+W039febaDnL5PWo/9d2Nvf37p84+Bd2voG2pQ53ja/I8SoBsR4J8fX0RGRmJsLAwbYdCREREWiDbJIiIiIjkjUkQERERyRKTICIiIpIlJkFEREQkS0yCiIiISJaYBBEREZEsMQkiIiIiWWISRERERLLEJIiIiIhkiUkQERERyRKTICIiIpIlJkFEREQkS0yCiIiISJaYBBEREZEsMQkiIiIiWWISRERERLLEJIiIiIhkiUkQERERyRKTICIiIpIlJkFEREQkS0yCiIiISJaYBBEREZEsMQkiIiIiWWISRERERLLEJIiIiIhkiUkQERERyRKTICIiIpKl9yIJ2rt3L5ycnODo6Iiff/5Z2+EQERFRGaCn7QCKKjMzE/7+/jh27BgsLCzQpEkT9OnTB1ZWVtoOjYiIiEqxMj8SdO7cOdSrVw+VK1eGqakpunTpgkOHDmk7LCIiIirltJ4EnTx5Ej169IC9vT0UCgV2796do05AQAAcHBxgZGSEZs2a4dy5c9K2R48eoXLlytL7ypUr4+HDhyUROhEREZVhWk+CUlJS0KBBAwQEBOS6fdu2bfD398eMGTNw4cIFNGjQAJ06dUJcXFwJR0pERETvE60nQV26dMHs2bPRp0+fXLcvXboUo0ePxvDhw+Hi4oLVq1fDxMQE69evBwDY29urjPw8fPgQ9vb2eR4vLS0NSUlJKi8iIiKSn1I9MTo9PR3nz5/H1KlTpTIdHR14eXkhNDQUAODh4YGrV6/i4cOHsLCwwIEDBzB9+vQ825w3bx6+++67Yo+dtC/0zjOV9541NTdZXlNtq9PO2/uUtNyO/3bcBY1RU59JQfqxOH8f3nUsdY8XGjipQPVytH1sXqGPBRTf7zXuFPA82r+jHXWp2R8FaatAfw+5fI4F6tsCxF2Q3xF1/115+/PINZ72U1XeFqidUkTrI0H5efr0KbKysmBra6tSbmtri5iYGACAnp4elixZgvbt26Nhw4aYOHFivivDpk6disTEROn14MGDYj0HIiIiKp1K9UhQQfXs2RM9e/YsUF1DQ0MYGhoWc0RERERU2pXqkSBra2vo6uoiNjZWpTw2NhZ2dnZaioqIiIjeB6U6CTIwMECTJk0QEhIilSmVSoSEhMDT01OLkREREVFZp/XLYcnJybh165b0Pjo6GhEREahQoQKqVasGf39/eHt7w93dHR4eHli2bBlSUlIwfPjwIh03ICAAAQEByMrKKuopEBERURmk9SQoPDwc7dv//9Rxf39/AIC3tzeCg4MxYMAAPHnyBN9++y1iYmLQsGFDHDx4MMdk6cLy9fWFr68vkpKSYGFhUaS2iIiIqOzRehLUrl07CCHyrePn5wc/P78SioiIiIjkoFTPCSIiIiIqLkyCiIiISJaYBBEREZEsyTYJCggIgIuLC5o2bartUIiIiEgLZJsE+fr6IjIyEmFhYdoOhYiIiLRAtkkQERERyRuTICIiIpIlJkFEREQkS1q/WaK2Zd+oMSkpSeNtp7xM03ibpL6klFc5yjT1GRWkbU3V0aTcjvcuucXzdjsFjVlTxy9IuwXpa00pSB/l6q1/h4qzH3OjqT5S93f27X+H1W6nmH6v1d1P7d+HAlD376Eg7eT4XsytnQJ8ZsXx/fpmu++64XJ+FKIoe78H/vvvP1StWlXbYRAREZEaHjx4gCpVqqi1r+yTIKVSiUePHsHMzAwKhUJj7SYlJaFq1ap48OABzM3NNdYu5Y19XrLY3yWPfV6y2N8lrzB9LoTAixcvYG9vDx0d9Wb3yP5ymI6OjtoZZEGYm5vzj6eEsc9LFvu75LHPSxb7u+QVtM+L+gB0TowmIiIiWWISRERERLLEJKiYGBoaYsaMGTA0NNR2KLLBPi9Z7O+Sxz4vWezvklfSfS77idFEREQkTxwJIiIiIlliEkRERESyxCSIiIiIZIlJEBEREckSk6BiEhAQAAcHBxgZGaFZs2Y4d+6ctkMqc+bNm4emTZvCzMwMNjY26N27N27evKlS59WrV/D19YWVlRVMTU3x0UcfITY2VqXO/fv30a1bN5iYmMDGxgaTJ09GZmZmSZ5KmTV//nwoFAqMHz9eKmOfa9bDhw8xdOhQWFlZwdjYGG5ubggPD5e2CyHw7bffolKlSjA2NoaXlxf+/fdflTaeP3+OIUOGwNzcHJaWlhg5ciSSk5NL+lTKhKysLEyfPh01atSAsbExatWqhVmzZqk8f4p9XjQnT55Ejx49YG9vD4VCgd27d6ts11T/Xr58Ga1bt4aRkRGqVq2KhQsXFj5YQRq3detWYWBgINavXy+uXbsmRo8eLSwtLUVsbKy2QytTOnXqJIKCgsTVq1dFRESE6Nq1q6hWrZpITk6W6nz++eeiatWqIiQkRISHh4vmzZuLFi1aSNszMzOFq6ur8PLyEhcvXhT79+8X1tbWYurUqdo4pTLl3LlzwsHBQdSvX1+MGzdOKmefa87z589F9erVhY+Pjzh79qy4c+eO+Ouvv8StW7ekOvPnzxcWFhZi9+7d4tKlS6Jnz56iRo0a4uXLl1Kdzp07iwYNGogzZ86Iv//+W9SuXVsMGjRIG6dU6s2ZM0dYWVmJvXv3iujoaLF9+3Zhamoqli9fLtVhnxfN/v37xbRp08TOnTsFALFr1y6V7Zro38TERGFrayuGDBkirl69KrZs2SKMjY3FmjVrChUrk6Bi4OHhIXx9faX3WVlZwt7eXsybN0+LUZV9cXFxAoA4ceKEEEKIhIQEoa+vL7Zv3y7VuX79ugAgQkNDhRCv/xh1dHRETEyMVGfVqlXC3NxcpKWllewJlCEvXrwQjo6O4vDhw6Jt27ZSEsQ+16yvv/5atGrVKs/tSqVS2NnZiUWLFkllCQkJwtDQUGzZskUIIURkZKQAIMLCwqQ6Bw4cEAqFQjx8+LD4gi+junXrJkaMGKFS1rdvXzFkyBAhBPtc095OgjTVvz/99JMoX768yr8pX3/9tXBycipUfLwcpmHp6ek4f/48vLy8pDIdHR14eXkhNDRUi5GVfYmJiQCAChUqAADOnz+PjIwMlb6uW7cuqlWrJvV1aGgo3NzcYGtrK9Xp1KkTkpKScO3atRKMvmzx9fVFt27dVPoWYJ9r2p49e+Du7o6PP/4YNjY2aNSoEdatWydtj46ORkxMjEp/W1hYoFmzZir9bWlpCXd3d6mOl5cXdHR0cPbs2ZI7mTKiRYsWCAkJQVRUFADg0qVL+Oeff9ClSxcA7PPipqn+DQ0NRZs2bWBgYCDV6dSpE27evIn4+PgCxyP7B6hq2tOnT5GVlaXyBQAAtra2uHHjhpaiKvuUSiXGjx+Pli1bwtXVFQAQExMDAwMDWFpaqtS1tbVFTEyMVCe3zyJ7G+W0detWXLhwAWFhYTm2sc81686dO1i1ahX8/f3xv//9D2FhYRg7diwMDAzg7e0t9Vdu/flmf9vY2Khs19PTQ4UKFdjfuZgyZQqSkpJQt25d6OrqIisrC3PmzMGQIUMAgH1ezDTVvzExMahRo0aONrK3lS9fvkDxMAmiMsHX1xdXr17FP//8o+1Q3msPHjzAuHHjcPjwYRgZGWk7nPeeUqmEu7s75s6dCwBo1KgRrl69itWrV8Pb21vL0b2ffvvtN2zevBm//vor6tWrh4iICIwfPx729vbscxni5TANs7a2hq6ubo7VMrGxsbCzs9NSVGWbn58f9u7di2PHjqFKlSpSuZ2dHdLT05GQkKBS/82+trOzy/WzyN5Gqs6fP4+4uDg0btwYenp60NPTw4kTJ/Djjz9CT08Ptra27HMNqlSpElxcXFTKnJ2dcf/+fQD/31/5/XtiZ2eHuLg4le2ZmZl4/vw5+zsXkydPxpQpUzBw4EC4ubnhk08+wYQJEzBv3jwA7PPipqn+1dS/M0yCNMzAwABNmjRBSEiIVKZUKhESEgJPT08tRlb2CCHg5+eHXbt24ejRozmGPps0aQJ9fX2Vvr558ybu378v9bWnpyeuXLmi8gd1+PBhmJub5/jyIaBjx464cuUKIiIipJe7uzuGDBki/cw+15yWLVvmuO1DVFQUqlevDgCoUaMG7OzsVPo7KSkJZ8+eVenvhIQEnD9/Xqpz9OhRKJVKNGvWrATOomxJTU2Fjo7qV5+uri6USiUA9nlx01T/enp64uTJk8jIyJDqHD58GE5OTgW+FAaAS+SLw9atW4WhoaEIDg4WkZGR4tNPPxWWlpYqq2Xo3b744gthYWEhjh8/Lh4/fiy9UlNTpTqff/65qFatmjh69KgIDw8Xnp6ewtPTU9qevVz7ww8/FBEREeLgwYOiYsWKXK5dCG+uDhOCfa5J586dE3p6emLOnDni33//FZs3bxYmJiZi06ZNUp358+cLS0tL8ccff4jLly+LXr165bqcuFGjRuLs2bPin3/+EY6OjlyunQdvb29RuXJlaYn8zp07hbW1tfjqq6+kOuzzonnx4oW4ePGiuHjxogAgli5dKi5evCju3bsnhNBM/yYkJAhbW1vxySefiKtXr4qtW7cKExMTLpEvLVasWCGqVasmDAwMhIeHhzhz5oy2QypzAOT6CgoKkuq8fPlSjBkzRpQvX16YmJiIPn36iMePH6u0c/fuXdGlSxdhbGwsrK2txcSJE0VGRkYJn03Z9XYSxD7XrD///FO4uroKQ0NDUbduXbF27VqV7UqlUkyfPl3Y2toKQ0ND0bFjR3Hz5k2VOs+ePRODBg0SpqamwtzcXAwfPly8ePGiJE+jzEhKShLjxo0T1apVE0ZGRqJmzZpi2rRpKkut2edFc+zYsVz/7fb29hZCaK5/L126JFq1aiUMDQ1F5cqVxfz58wsdq0KIN26TSURERCQTnBNEREREssQkiIiIiGSJSRARERHJEpMgIiIikiUmQURERCRLTIKIiIhIlpgEERERkSwxCSKi95KDgwOWLVum7TCIqBRjEkREeQoNDYWuri66deum7VCIiDSOSRAR5SkwMBBffvklTp48iUePHmk7nPfamw+CJKKSwSSIiHKVnJyMbdu24YsvvkC3bt0QHByssv348eNQKBQICQmBu7s7TExM0KJFixxPRV+1ahVq1aoFAwMDODk54ZdfflHZrlAosGbNGnTv3h0mJiZwdnZGaGgobt26hXbt2qFcuXJo0aIFbt++Le1z+/Zt9OrVC7a2tjA1NUXTpk1x5MiRPM9lxIgR6N69u0pZRkYGbGxsEBgYmOs+9+7dQ48ePVC+fHmUK1cO9erVw/79+6Xt165dQ/fu3WFubg4zMzO0bt1ailGpVOL7779HlSpVYGhoiIYNG+LgwYPSvnfv3oVCocC2bdvQtm1bGBkZYfPmzQCAn3/+Gc7OzjAyMkLdunXx008/5XleRFREaj4fjYjec4GBgcLd3V0I8fohn7Vq1RJKpVLanv2QxGbNmonjx4+La9euidatW4sWLVpIdXbu3Cn09fVFQECAuHnzpliyZInQ1dUVR48eleoAEJUrVxbbtm0TN2/eFL179xYODg6iQ4cO4uDBgyIyMlI0b95cdO7cWdonIiJCrF69Wly5ckVERUWJb775RhgZGUlPqRZCiOrVq4sffvhBCCHEqVOnhK6urnj06JFKbOXKlcvzoZfdunUTH3zwgbh8+bK4ffu2+PPPP8WJEyeEEEL8999/okKFCqJv374iLCxM3Lx5U6xfv17cuHFDCCHE0qVLhbm5udiyZYu4ceOG+Oqrr4S+vr6IiooSQggRHR0tAAgHBwexY8cOcefOHfHo0SOxadMmUalSJalsx44dokKFCiI4OFitz5CI8sckiIhy1aJFC7Fs2TIhhBAZGRnC2tpaHDt2TNqenQQdOXJEKtu3b58AIF6+fCm1MXr0aJV2P/74Y9G1a1fpPQDxzTffSO9DQ0MFABEYGCiVbdmyRRgZGeUbb7169cSKFSuk928mQUII4eLiIhYsWCC979Gjh/Dx8cmzPTc3NzFz5sxct02dOlXUqFFDpKen57rd3t5ezJkzR6WsadOmYsyYMUKI/0+Csvs3W61atcSvv/6qUjZr1izh6emZZ5xEpD5eDiOiHG7evIlz585h0KBBAAA9PT0MGDAg10tH9evXl36uVKkSACAuLg4AcP36dbRs2VKlfsuWLXH9+vU827C1tQUAuLm5qZS9evUKSUlJAF5fqps0aRKcnZ1haWkJU1NTXL9+Hffv38/znEaNGoWgoCAAQGxsLA4cOIARI0bkWX/s2LGYPXs2WrZsiRkzZuDy5cvStoiICLRu3Rr6+vo59ktKSsKjR48KdN7u7u7SzykpKbh9+zZGjhwJU1NT6TV79myVS4FEpDl62g6AiEqfwMBAZGZmwt7eXioTQsDQ0BArV66EhYWFVP5mIqBQKAC8nhNTGLm1kV+7kyZNwuHDh7F48WLUrl0bxsbG6NevH9LT0/M8xrBhwzBlyhSEhobi9OnTqFGjBlq3bp1n/VGjRqFTp07Yt28fDh06hHnz5mHJkiX48ssvYWxsXKjzy0u5cuWkn5OTkwEA69atQ7NmzVTq6erqauR4RKSKI0FEpCIzMxMbN27EkiVLEBERIb0uXboEe3t7bNmypcBtOTs749SpUyplp06dgouLS5FiPHXqFHx8fNCnTx+4ubnBzs4Od+/ezXcfKysr9O7dG0FBQQgODsbw4cPfeZyqVavi888/x86dOzFx4kSsW7cOwOuRq7///jvXFV3m5uawt7cv9Hnb2trC3t4ed+7cQe3atVVeNWrUeGesRFR4HAkiIhV79+5FfHw8Ro4cqTLiAwAfffQRAgMD8fnnnxeorcmTJ6N///5o1KgRvLy88Oeff2Lnzp35ruQqCEdHR+zcuRM9evSAQqHA9OnTCzT6NGrUKHTv3h1ZWVnw9vbOt+748ePRpUsX1KlTB/Hx8Th27BicnZ0BAH5+flixYgUGDhyIqVOnwsLCAmfOnIGHhwecnJwwefJkzJgxA7Vq1ULDhg0RFBSEiIgIaQVYXr777juMHTsWFhYW6Ny5M9LS0hAeHo74+Hj4+/sXvIOIqECYBBGRisDAQHh5eeVIgIDXSdDChQtV5sfkp3fv3li+fDkWL16McePGoUaNGggKCkK7du2KFOPSpUsxYsQItGjRAtbW1vj666+l+UL58fLyQqVKlVCvXj2VS325ycrKgq+vL/777z+Ym5ujc+fO+OGHHwC8HlU6evQoJk+ejLZt20JXVxcNGzaU5gGNHTsWiYmJmDhxIuLi4uDi4oI9e/bA0dEx32OOGjUKJiYmWLRoESZPnoxy5crBzc0N48ePL1jHEFGhKIQQQttBEBGVhOTkZFSuXBlBQUHo27evtsMhIi3jSBARvfeUSiWePn2KJUuWwNLSEj179tR2SERUCjAJIqL33v3791GjRg1UqVIFwcHB0NPjP31ExMthREREJFNcIk9ERESyxCSIiIiIZIlJEBEREckSkyAiIiKSJSZBREREJEtMgoiIiEiWmAQRERGRLDEJIiIiIlliEkRERESy9H9URSItNvE9PQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scripts.train_detector(\n",
    "    cp_task, detector, save_path=None, eval_batch_size=64, batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Edge Attribution Patching on Hex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eap.eap_wrapper import EAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: look back at edge attribution example\n",
    "model.set_use_split_qkv_input(True)\n",
    "model.set_use_attn_result(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use mean probability over effect tokens as metric \n",
    "def effect_prob_func(logits, effect_tokens):\n",
    "    assert logits.ndim == 3\n",
    "    probs = logits.softmax(-1)\n",
    "    # Sum over vocab and batch dim (for now we're just computing attribution values, we'll deal with per data instance later)\n",
    "    out = probs[:, -1, effect_tokens].mean()\n",
    "    print(\"metric\", out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "effect_tokens = torch.tensor(task[\"effect_tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "trusted_tokens = torch.stack(\n",
    "    [torch.tensor(x[\"prefix_tokens\"]) for x in cp_task.trusted_data.data], \n",
    "    dim=0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving activations requires 0.0001 GB of memory per token\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/256 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Cannot add hook blocks.0.hook_mlp_in if use_hook_mlp_in is False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mreset_hooks()\n\u001b[0;32m----> 3\u001b[0m graph \u001b[38;5;241m=\u001b[39m \u001b[43mEAP\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclean_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrusted_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43meffect_prob_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffect_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meffect_tokens\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# upstream_nodes=[\"head\"],\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# downstream_nodes=[\"head\"],\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/elk-experiments/edge-attribution-patching/eap/eap_wrapper.py:166\u001b[0m, in \u001b[0;36mEAP\u001b[0;34m(model, clean_tokens, metric, corrupted_tokens, upstream_nodes, downstream_nodes, batch_size)\u001b[0m\n\u001b[1;32m    164\u001b[0m model\u001b[38;5;241m.\u001b[39mreset_hooks()\n\u001b[1;32m    165\u001b[0m model\u001b[38;5;241m.\u001b[39madd_hook(upstream_hook_filter, clean_upstream_hook_fn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfwd\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 166\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdownstream_hook_filter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean_downstream_hook_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbwd\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m clean_tokens \u001b[38;5;241m=\u001b[39m clean_tokens\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    169\u001b[0m value \u001b[38;5;241m=\u001b[39m metric(model(clean_tokens[idx:idx\u001b[38;5;241m+\u001b[39mbatch_size], return_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/elk-experiments-AZ2LBS3Q-py3.10/lib/python3.10/site-packages/transformer_lens/hook_points.py:316\u001b[0m, in \u001b[0;36mHookedRootModule.add_hook\u001b[0;34m(self, name, hook, dir, is_permanent, level, prepend)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook_point_name, hp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name(hook_point_name):\n\u001b[0;32m--> 316\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_and_add_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhook_point_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhook\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mdir\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdir\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_permanent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_permanent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprepend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/elk-experiments-AZ2LBS3Q-py3.10/lib/python3.10/site-packages/transformer_lens/hook_points.py:267\u001b[0m, in \u001b[0;36mHookedRootModule.check_and_add_hook\u001b[0;34m(self, hook_point, hook_point_name, hook, dir, is_permanent, level, prepend)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_and_add_hook\u001b[39m(\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    257\u001b[0m     hook_point: HookPoint,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m     prepend: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    264\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    265\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Runs checks on the hook, and then adds it to the hook point\"\"\"\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_hooks_to_add\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhook_point\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhook_point_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhook\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mdir\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdir\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_permanent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_permanent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprepend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m     hook_point\u001b[38;5;241m.\u001b[39madd_hook(hook, \u001b[38;5;28mdir\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdir\u001b[39m, is_permanent\u001b[38;5;241m=\u001b[39mis_permanent, level\u001b[38;5;241m=\u001b[39mlevel, prepend\u001b[38;5;241m=\u001b[39mprepend)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/elk-experiments-AZ2LBS3Q-py3.10/lib/python3.10/site-packages/transformer_lens/HookedTransformer.py:237\u001b[0m, in \u001b[0;36mHookedTransformer.check_hooks_to_add\u001b[0;34m(self, hook_point, hook_point_name, hook, dir, is_permanent, prepend)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    234\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39muse_split_qkv_input\n\u001b[1;32m    235\u001b[0m     ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot add hook \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_point_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m if use_split_qkv_input is False\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hook_point_name\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlp_in\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 237\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    238\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39muse_hook_mlp_in\n\u001b[1;32m    239\u001b[0m     ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot add hook \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_point_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m if use_hook_mlp_in is False\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hook_point_name\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattn_in\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39muse_attn_in\n\u001b[1;32m    243\u001b[0m     ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot add hook \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_point_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m if use_attn_in is False\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Cannot add hook blocks.0.hook_mlp_in if use_hook_mlp_in is False"
     ]
    }
   ],
   "source": [
    "model.reset_hooks()\n",
    "\n",
    "graph = EAP(\n",
    "    model=model,\n",
    "    clean_tokens=trusted_tokens,\n",
    "    metric=partial(effect_prob_func, effect_tokens=effect_tokens), \n",
    "    # upstream_nodes=[\"head\"],\n",
    "    # downstream_nodes=[\"head\"],\n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_edges = graph.top_edges(n=20, abs_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head.2.7 -> [0.0] -> head.3.0.k\n",
      "head.0.6 -> [-0.0] -> head.1.1.v\n",
      "head.2.7 -> [0.0] -> head.3.3.k\n",
      "head.0.6 -> [0.0] -> head.1.0.v\n",
      "head.0.0 -> [0.0] -> head.2.1.v\n",
      "head.0.6 -> [-0.0] -> head.2.7.v\n",
      "head.0.0 -> [-0.0] -> head.3.4.v\n",
      "head.0.6 -> [-0.0] -> head.1.3.v\n",
      "head.0.5 -> [0.0] -> head.1.3.v\n",
      "head.0.0 -> [0.0] -> head.2.7.v\n",
      "head.0.6 -> [-0.0] -> head.2.1.v\n",
      "head.0.0 -> [-0.0] -> head.3.3.v\n",
      "head.1.3 -> [0.0] -> head.2.7.v\n",
      "head.0.6 -> [-0.0] -> head.1.4.v\n",
      "head.0.6 -> [-0.0] -> head.2.5.v\n",
      "head.2.7 -> [0.0] -> head.3.0.q\n",
      "head.0.3 -> [0.0] -> head.2.7.v\n",
      "head.0.3 -> [-0.0] -> head.1.7.v\n",
      "head.1.3 -> [-0.0] -> head.2.5.v\n",
      "head.1.3 -> [0.0] -> head.3.0.q\n"
     ]
    }
   ],
   "source": [
    "#TODO: fix the edge attribution code (maybe missing a negative? should trace through)\n",
    "for from_edge, to_edge, score in top_edges:\n",
    "    print(f'{from_edge} -> [{round(score, 3)}] -> {to_edge}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elk-experiments-AZ2LBS3Q-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
