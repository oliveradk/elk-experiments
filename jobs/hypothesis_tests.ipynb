{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from datetime import datetime\n",
    "\n",
    "import submitit \n",
    "\n",
    "from auto_circuit.tasks import (\n",
    "    IOI_COMPONENT_CIRCUIT_TASK, \n",
    "    IOI_GPT2_AUTOENCODER_COMPONENT_CIRCUIT_TASK, \n",
    "    DOCSTRING_TOKEN_CIRCUIT_TASK, \n",
    "    DOCSTRING_COMPONENT_CIRCUIT_TASK, \n",
    "    GREATERTHAN_COMPONENT_CIRCUIT_TASK, \n",
    "    GREATERTHAN_GPT2_AUTOENCODER_COMPONENT_CIRCUIT_TASK, \n",
    ")\n",
    "from elk_experiments.utils import repo_path_to_abs_path, OUTPUT_DIR\n",
    "from elk_experiments.auto_circuit.tasks import IOI_TOKEN_CIRCUIT_TASK\n",
    "from auto_circuit.types import AblationType\n",
    "from elk_experiments.auto_circuit.score_funcs import GradFunc, AnswerFunc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify Settings / Hyperpameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify the hyperparameters\n",
    "tasks = [\n",
    "    IOI_TOKEN_CIRCUIT_TASK, \n",
    "    IOI_COMPONENT_CIRCUIT_TASK, \n",
    "    DOCSTRING_TOKEN_CIRCUIT_TASK, \n",
    "    DOCSTRING_COMPONENT_CIRCUIT_TASK, \n",
    "    GREATERTHAN_COMPONENT_CIRCUIT_TASK, \n",
    "    # IOI_GPT2_AUTOENCODER_COMPONENT_CIRCUIT_TASK, \n",
    "    # GREATERTHAN_GPT2_AUTOENCODER_COMPONENT_CIRCUIT_TASK, \n",
    "    # ANIMAL_DIET_GPT2_AUTOENCODER_COMPONENT_CIRCUIT_TASK\n",
    "]\n",
    "use_abs = [True, False]\n",
    "ablation_types = [\n",
    "    AblationType.RESAMPLE, \n",
    "    AblationType.TOKENWISE_MEAN_CLEAN,\n",
    "    AblationType.TOKENWISE_MEAN_CORRUPT, \n",
    "    AblationType.TOKENWISE_MEAN_CLEAN_AND_CORRUPT,\n",
    "    # AblationType.ZERO\n",
    "]\n",
    "grad_funcs = [\n",
    "    GradFunc.LOGIT, \n",
    "    GradFunc.LOGPROB\n",
    "]\n",
    "answer_funcs = [\n",
    "    AnswerFunc.MAX_DIFF, \n",
    "    AnswerFunc.AVG_VAL\n",
    "]\n",
    "\n",
    "use_abs_to_epsilon = {\n",
    "    True: [0.1], \n",
    "    False: [0.0, -0.4]\n",
    "}\n",
    "\n",
    "# generate all combinations\n",
    "combinations = [\n",
    "    {\n",
    "        \"task\": f\"'{task.key}'\",\n",
    "        \"use_abs\": use_ab,\n",
    "        \"ablation_type\": ablation_type.name,\n",
    "        \"grad_func\": grad_func.name,\n",
    "        \"answer_func\": answer_func.name,\n",
    "        \"epsilon\": epsilon\n",
    "    }\n",
    "    for task, use_ab, ablation_type, grad_func, answer_func in itertools.product(\n",
    "        tasks,\n",
    "        use_abs,\n",
    "        ablation_types,\n",
    "        grad_funcs,\n",
    "        answer_funcs\n",
    "    )\n",
    "    for epsilon in use_abs_to_epsilon[use_ab]\n",
    "]\n",
    "\n",
    "# combinations = [\n",
    "#     {\n",
    "#         \"task\": f\"'{IOI_TOKEN_CIRCUIT_TASK.key}'\",\n",
    "#         \"use_abs\": False,\n",
    "#         \"ablation_type\": AblationType.TOKENWISE_MEAN_CORRUPT.name,\n",
    "#         \"grad_func\": GradFunc.LOGPROB.name,\n",
    "#         \"answer_func\": AnswerFunc.AVG_VAL.name,\n",
    "#         \"epsilon\": 0.0\n",
    "#     }\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Executor and Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nas/ucb/oliveradk/miniforge3/envs/elk-experiments/lib/python3.10/site-packages/submitit/auto/auto.py:23: UserWarning: Setting 'gres' is deprecated. Use 'slurm_gres' instead.\n",
      "  warnings.warn(f\"Setting '{arg}' is deprecated. Use '{new_arg}' instead.\")\n"
     ]
    }
   ],
   "source": [
    "# setup the executor\n",
    "out_dir = repo_path_to_abs_path(OUTPUT_DIR / \"hypo_test_out_logs\" / datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "out_dir.mkdir(exist_ok=True, parents=True)\n",
    "executor = submitit.AutoExecutor(folder=out_dir)\n",
    "num_jobs_parallel = 8\n",
    "executor.update_parameters(\n",
    "    timeout_min=60*24,\n",
    "    mem_gb=40,\n",
    "    gres=\"gpu:1\",\n",
    "    cpus_per_task=8,\n",
    "    nodes=1,\n",
    "    slurm_qos=\"high\", \n",
    "    slurm_array_parallelism=num_jobs_parallel\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the jobs\n",
    "with executor.batch():\n",
    "    jobs = []\n",
    "    for combo in combinations:\n",
    "        function = submitit.helpers.CommandFunction(\n",
    "            [\"python\", \"scripts/hypothesis_tests.py\"] + [\n",
    "                f\"{key}={value}\" for key, value in combo.items()\n",
    "            ], \n",
    "            cwd=repo_path_to_abs_path(\".\")\n",
    "        )\n",
    "        jobs.append(executor.submit(function))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submitit INFO (2024-08-14 15:22:36,045) - Starting with JobEnvironment(job_id=432143_47, hostname=ppo.ist.berkeley.edu, local_rank=0(1), node=0(1), global_rank=0(1))\n",
      "submitit INFO (2024-08-14 15:22:36,045) - Loading pickle: /nas/ucb/oliveradk/elk-experiments/output/hypo_test_out_logs/2024-08-14_14-45-35/432143_47_submitted.pkl\n",
      "The following command is sent: \"python scripts/hypothesis_tests.py task='Indirect Object Identification Component Circuit' use_abs=False ablation_type=TOKENWISE_MEAN_CLEAN_AND_CORRUPT grad_func=LOGPROB answer_func=AVG_VAL epsilon=-0.4\"\n",
      "Loaded pretrained model gpt2-small into HookedTransformer\n",
      "seq_len before divergence None\n",
      "seq_len after divergence None\n",
      "Saving cache to /nas/ucb/oliveradk/elk-experiments/output/hypo_test_results/Indirect_Object_Identification_Component_Circuit_TOKENWISE_MEAN_CLEAN_AND_CORRUPT_LOGPROB_AVG_VAL_10/False_0.05_-0.4_0.9/prune_scores-14-08-2024_15-23-13.pkl\n",
      "interval: 0 - 32491\n",
      "width 1000\n",
      "interval: 32000 - 32491\n",
      "width 100\n",
      "interval: 32400 - 32491\n",
      "width 10\n",
      "interval: 32480 - 32490\n",
      "width 1\n",
      "Saving json to /nas/ucb/oliveradk/elk-experiments/output/hypo_test_results/Indirect_Object_Identification_Component_Circuit_TOKENWISE_MEAN_CLEAN_AND_CORRUPT_LOGPROB_AVG_VAL_10/False_0.05_-0.4_0.9/equiv_results.json\n",
      "Saving json to /nas/ucb/oliveradk/elk-experiments/output/hypo_test_results/Indirect_Object_Identification_Component_Circuit_TOKENWISE_MEAN_CLEAN_AND_CORRUPT_LOGPROB_AVG_VAL_10/False_0.05_-0.4_0.9/equiv_test_result.json\n",
      "Saving json to /nas/ucb/oliveradk/elk-experiments/output/hypo_test_results/Indirect_Object_Identification_Component_Circuit_TOKENWISE_MEAN_CLEAN_AND_CORRUPT_LOGPROB_AVG_VAL_10/False_0.05_-0.4_0.9/edges.json\n",
      "Saving json to /nas/ucb/oliveradk/elk-experiments/output/hypo_test_results/Indirect_Object_Identification_Component_Circuit_TOKENWISE_MEAN_CLEAN_AND_CORRUPT_LOGPROB_AVG_VAL_10/False_0.05_-0.4_0.9/valid_edges.json\n",
      "Saving json to /nas/ucb/oliveradk/elk-experiments/output/hypo_test_results/Indirect_Object_Identification_Component_Circuit_TOKENWISE_MEAN_CLEAN_AND_CORRUPT_LOGPROB_AVG_VAL_10/False_0.05_-0.4_0.9/valid_edges_equiv_result.json\n",
      "Saving json to /nas/ucb/oliveradk/elk-experiments/output/hypo_test_results/Indirect_Object_Identification_Component_Circuit_TOKENWISE_MEAN_CLEAN_AND_CORRUPT_LOGPROB_AVG_VAL_10/False_0.05_-0.4_0.9/min_test_results.json\n",
      "Saving json to /nas/ucb/oliveradk/elk-experiments/output/hypo_test_results/Indirect_Object_Identification_Component_Circuit_TOKENWISE_MEAN_CLEAN_AND_CORRUPT_LOGPROB_AVG_VAL_10/False_0.05_-0.4_0.9/min_test_sampled_results.json\n",
      "Saving json to /nas/ucb/oliveradk/elk-experiments/output/hypo_test_results/Indirect_Object_Identification_Component_Circuit_TOKENWISE_MEAN_CLEAN_AND_CORRUPT_LOGPROB_AVG_VAL_10/False_0.05_-0.4_0.9/indep_result.json\n",
      "submitit INFO (2024-08-14 15:33:30,606) - Job completed successfully\n",
      "submitit INFO (2024-08-14 15:33:30,609) - Exiting after successful completion\n",
      "\n"
     ]
    }
   ],
   "source": [
    "job = jobs[47]\n",
    "# read stdout and stderr\n",
    "print(job.stdout())\n",
    "# print(job.stderr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task': \"'Indirect Object Identification Token Circuit'\",\n",
       " 'use_abs': True,\n",
       " 'ablation_type': 'RESAMPLE',\n",
       " 'grad_func': 'LOGIT',\n",
       " 'answer_func': 'MAX_DIFF',\n",
       " 'epsilon': 0.1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.375"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combinations) / num_jobs_parallel * 7 / 60 # roughly 4 hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysize Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pathologies of Ablations and Score Functions\n",
    "\n",
    "- explore some examples on IOI in depth, show how e.g. mean clean ablation just attends from source to test for avg val, similar for max value\n",
    "- zero ablation requires almost every edge, too out of distribution\n",
    "- mean corrupt leads to more \"task identification\" mechanisms\n",
    "- resample ablation allows for patching edges not reached by input, is in this sense more natural (someone has said this before), but also higher variance and less general (constructing contrast pairs is expensive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synergies Between Score Functions and Ablation Methodologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to plot fraction of edges required for faithfulness, with bar plot seperated by ablation methodology and and score func (\n",
    "    # generate different plot per answer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from auto_circuit.tasks import Task\n",
    "def get_exp_dir(\n",
    "    task_key: str,\n",
    "    ablation_type: AblationType,\n",
    "    grad_func: GradFunc,\n",
    "    answer_func: AnswerFunc,\n",
    "    ig_samples: int, \n",
    "    use_abs: bool,\n",
    "    alpha: float,\n",
    "    epsilon: float,\n",
    "    q_star: float\n",
    "):\n",
    "    return repo_path_to_abs_path(\n",
    "        OUTPUT_DIR / \"hypo_test_results\" / f\"{task_key.replace(' ', '_')}_{ablation_type.name}_{grad_func.name}_{answer_func.name}_{ig_samples}\" / f\"{use_abs}_{alpha}_{epsilon}_{q_star}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "ig_default = 10\n",
    "alpha_default = 0.05\n",
    "q_star_default = 0.9\n",
    "# epsilon_default = use_abs_to_epsilon[use_abs_default][0]\n",
    "# grad_func_default = GradFunc.LOGPROB\n",
    "# tasks = [IOI_TOKEN_CIRCUIT_TASK, DOCSTRING_TOKEN_CIRCUIT_TASK]\n",
    "# answer_funcs = [AnswerFunc.MAX_DIFF, AnswerFunc.AVG_VAL]\n",
    "# ablation_types = ablation_types\n",
    "\n",
    "# log frac of total edges needed \n",
    "\n",
    "frac_total_edges = defaultdict(dict) # dictionary from \n",
    "for combo in combinations:\n",
    "    task_key = combo[\"task\"][1:-1] # strip quotes\n",
    "    ablation_type = AblationType[combo[\"ablation_type\"]]\n",
    "    grad_func_default = GradFunc[combo[\"grad_func\"]]\n",
    "    answer_func = AnswerFunc[combo[\"answer_func\"]]\n",
    "    use_ab = combo[\"use_abs\"]\n",
    "    epsilon = combo[\"epsilon\"]\n",
    "    # get path to results \n",
    "    exp_path = get_exp_dir(task_key, ablation_type, grad_func_default, answer_func, ig_default, use_ab, alpha_default, epsilon, q_star_default)\n",
    "    # load equiv test results \n",
    "    with open(exp_path / \"equiv_results.json\", \"r\") as f:\n",
    "        equiv_test_results: dict[int, dict] = json.load(f)\n",
    "    total_edges = max([int(edge_count) for edge_count in equiv_test_results.keys()])\n",
    "    equivs = [int(edge_count) for edge_count, result in equiv_test_results.items() if not result[\"not_equiv\"]]\n",
    "    min_equiv = min(equivs) if len(equivs) > 0 else total_edges\n",
    "    frac_total_edges[(task_key, use_ab, epsilon)][(ablation_type, answer_func)] = (min_equiv / total_edges, min_equiv, total_edges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All figures have been generated and saved.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "scale = 'log' \n",
    "# scale = 'linear'\n",
    "\n",
    "def limit_image_size(fig, ax, max_size=65000):  # 2^16 - 1 = 65535, we use 65000 for safety\n",
    "    while True:\n",
    "        fig.canvas.draw()  # Render the figure\n",
    "        width, height = fig.canvas.get_width_height()\n",
    "        if width <= max_size and height <= max_size:\n",
    "            break\n",
    "        # If too large, reduce figure size\n",
    "        fig_size = fig.get_size_inches()\n",
    "        fig.set_size_inches(fig_size[0] * 0.9, fig_size[1] * 0.9)\n",
    "    return fig, ax\n",
    "\n",
    "# Preparing data for plotting\n",
    "ablation_answer_combinations = list(itertools.product(ablation_types, answer_funcs))\n",
    "\n",
    "# Create a figure for each combination of epsilon and use_ab\n",
    "for use_ab in use_abs:\n",
    "    for epsilon in use_abs_to_epsilon[use_ab]:\n",
    "        # Filter task combinations for current use_ab and epsilon\n",
    "        task_combos = [\n",
    "            (task.key, use_ab, epsilon) \n",
    "            for task in tasks\n",
    "        ]\n",
    "        n_tasks = len(task_combos)\n",
    "        n_combinations = len(ablation_answer_combinations)\n",
    "\n",
    "        # Create a new figure for each combination\n",
    "        fig, ax = plt.subplots(figsize=(16, 9), dpi=100)  # Start with a smaller figure size\n",
    "        index = np.arange(n_tasks)\n",
    "        bar_width = 0.8 / n_combinations\n",
    "        opacity = 0.8\n",
    "\n",
    "        for i, combination in enumerate(ablation_answer_combinations):\n",
    "            values = [frac_total_edges[task_combo][combination][0] for task_combo in task_combos]\n",
    "            labels = [frac_total_edges[task_combo][combination][1] for task_combo in task_combos]\n",
    "            \n",
    "            # Adjust the position of each group of bars\n",
    "            position = index + (i - n_combinations/2 + 0.5) * bar_width\n",
    "            \n",
    "            bars = ax.bar(position, values, bar_width,\n",
    "                          alpha=opacity,\n",
    "                          label=f'{combination[0]} & {combination[1]}')\n",
    "\n",
    "            # Adding labels above each bar (removed for simplicity and size reduction)\n",
    "            # for bar, label in zip(bars, labels):\n",
    "            #     ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), label,\n",
    "            #             ha='center', va='bottom', rotation=90, fontsize=6)\n",
    "\n",
    "        # Labels and titles\n",
    "        ax.set_xlabel('Tasks')\n",
    "        ax.set_ylabel('Fraction of Total Edges')\n",
    "        ax.set_title(f'Fraction of Total Edges by Task (use_ab={use_ab}, epsilon={epsilon})')\n",
    "        ax.set_xticks(index)\n",
    "        ax.set_xticklabels([task_combo[0] for task_combo in task_combos], rotation=90, ha='center', fontsize=8)\n",
    "        \n",
    "        # Move the legend outside the plot\n",
    "        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0., fontsize=8)\n",
    "\n",
    "        ax.set_yscale(scale)\n",
    "\n",
    "        # Adjust the layout to make room for the legend\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(right=0.75)\n",
    "\n",
    "        # Limit the image size\n",
    "        fig, ax = limit_image_size(fig, ax)\n",
    "\n",
    "        # Save the figure with controlled size\n",
    "        plt.savefig(f'fraction_edges_use_ab_{use_ab}_epsilon_{epsilon}.png', \n",
    "                    bbox_inches='tight', \n",
    "                    dpi=100)\n",
    "        plt.close(fig)\n",
    "\n",
    "print(\"All figures have been generated and saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimality / Completeness Tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elk-experiments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
